{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7bca9b",
   "metadata": {},
   "source": [
    "# CS336 Assignments\n",
    "\n",
    "| # | Topic                         | Description                                 |\n",
    "|---|-------------------------------|---------------------------------------------|\n",
    "| 1 | Basics                        | Train an LLM from scratch                   |\n",
    "| 2 | Systems                       | Make it run fast!                           |\n",
    "| 3 | Scaling                       | Make it performant at a FLOP budget         |\n",
    "| 4 | Data                          | Prepare the right datasets                  |\n",
    "| 5 | Alignment & Reasoning RL      | Align it to real-world use cases            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f19a5c",
   "metadata": {},
   "source": [
    "### Assignment #1\n",
    "- Implement all of the components (tokenizer, model, loss function, optimizer) necessary to train a standard Transformer language model\n",
    "- Train a minimal language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fad44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from datasets import load_dataset\n",
    "import joblib\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29cb95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 97,\n",
       " 'b': 98,\n",
       " 'c': 99,\n",
       " 'd': 100,\n",
       " 'e': 101,\n",
       " 'f': 102,\n",
       " 'g': 103,\n",
       " 'h': 104,\n",
       " 'i': 105,\n",
       " 'j': 106,\n",
       " 'k': 107,\n",
       " 'l': 108,\n",
       " 'm': 109,\n",
       " 'n': 110,\n",
       " 'o': 111,\n",
       " 'p': 112,\n",
       " 'q': 113,\n",
       " 'r': 114,\n",
       " 's': 115,\n",
       " 't': 116,\n",
       " 'u': 117,\n",
       " 'v': 118,\n",
       " 'w': 119,\n",
       " 'x': 120,\n",
       " 'y': 121,\n",
       " 'z': 122,\n",
       " 'A': 65,\n",
       " 'B': 66,\n",
       " 'C': 67,\n",
       " 'D': 68,\n",
       " 'E': 69,\n",
       " 'F': 70,\n",
       " 'G': 71,\n",
       " 'H': 72,\n",
       " 'I': 73,\n",
       " 'J': 74,\n",
       " 'K': 75,\n",
       " 'L': 76,\n",
       " 'M': 77,\n",
       " 'N': 78,\n",
       " 'O': 79,\n",
       " 'P': 80,\n",
       " 'Q': 81,\n",
       " 'R': 82,\n",
       " 'S': 83,\n",
       " 'T': 84,\n",
       " 'U': 85,\n",
       " 'V': 86,\n",
       " 'W': 87,\n",
       " 'X': 88,\n",
       " 'Y': 89,\n",
       " 'Z': 90}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_letters\n",
    "\n",
    "{l: ord(l) for l in ascii_letters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82da92ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(115)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd26ea",
   "metadata": {},
   "source": [
    "### Exercise 1: Problem (unicode1): Understanding Unicode (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92f1886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81842e52",
   "metadata": {},
   "source": [
    "This represents a null character often used to represent end of a string. It is also called an escape sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd338fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\x00'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr('\\x00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cc439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "382b1b51",
   "metadata": {},
   "source": [
    "The string representation of this character is '\\x00'. When this string is passed to print function, it's rendered as null as that is the purpose of this character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb1d013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c1bdc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edeebc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12691eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5f80c",
   "metadata": {},
   "source": [
    "When we print the character with the print function, the character is executed and hence renders nothing on the stdout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32a387",
   "metadata": {},
   "source": [
    "### Exercise 2: Problem (unicode2): Unicode Encodings (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fddecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_string_encoded: b'Hello'\n",
      "Byte values: [72, 101, 108, 108, 111]\n",
      "test string decoded: Hello\n"
     ]
    }
   ],
   "source": [
    "test_string = \"Hello\"\n",
    "test_string_encoded = test_string.encode(\"UTF-8\")\n",
    "print(f\"test_string_encoded: {test_string_encoded}\")\n",
    "print(f\"Byte values: {list(test_string_encoded)}\")\n",
    "print(f\"test string decoded: {test_string_encoded.decode(\"UTF-8\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bca8fe",
   "metadata": {},
   "source": [
    "(a) What are some reasons to prefer training our tokenizer on UTF-8 encoded bytes, rather than\n",
    "UTF-16 or UTF-32? It may be helpful to compare the output of these encodings for various\n",
    "input strings\n",
    "\n",
    "A: Majority of the internet comprises of UTF-8 characters. And, UTF-8 is space efficient as 5 characters in UTF-8 takes 5 bytes whereas UTF-16 and UTF-32 takes 2x and 4x the bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b7879d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcafé\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "decode_utf8_bytes_to_str_wrong(\"café\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f465a",
   "metadata": {},
   "source": [
    "The function attempts to convert each character as a standalone single character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc26adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"café\".encode(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93e0a7",
   "metadata": {},
   "source": [
    "## Exercise 3: Problem (train_bpe): BPE Tokenizer Training (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eaf49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(input_path, vocab_size=1000, special_tokens=[]):\n",
    "    vocab, merges = None, None\n",
    "\n",
    "    return vocab, merges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaef1b9",
   "metadata": {},
   "source": [
    "## Exercise 4: Problem (train_bpe_tinystories): BPE Training on TinyStories (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9f3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe_tinystories(input_path, vocab_size=10000, special_tokens=[\"|endoftext|\"]):\n",
    "    vocab, merges = None, None\n",
    "\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e844a74",
   "metadata": {},
   "source": [
    "## Exercise 5: Problem (train_bpe_expts_owt): BPE Training on OpenWebText (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "647fe501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe_expts_owt(input_path, vocab_size=32000, special_tokens=[\"|endoftext|\"]):\n",
    "    vocab, merges = None, None\n",
    "\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01767cd1",
   "metadata": {},
   "source": [
    "## Exercise 6: Problem (tokenizer): Implementing the tokenizer (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd29c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPETokkenizer():\n",
    "    def __init__(self, vocab, merges, special_tokens=None):\n",
    "        pass\n",
    "\n",
    "    def encode(self, text:str):\n",
    "        pass\n",
    "\n",
    "    def decode(self, ids:list[str]):\n",
    "        pass\n",
    "\n",
    "    def from_files():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3652ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2771b5a7",
   "metadata": {},
   "source": [
    "## Exercise 7: Problem (tokenizer_experiments): Experiments with tokenizers (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68591549",
   "metadata": {},
   "source": [
    "a. Sample 10 documents from TinyStories and OpenWebText. Using your previously-trained TinyStories and OpenWebText tokenizers (10K and 32K vocabulary size, respectively), encode these sampled documents into integer IDs. What is each tokenizer’s compression ratio (bytes/token)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1a20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867e2c53",
   "metadata": {},
   "source": [
    "b. What happens if you tokenize your OpenWebText sample with the TinyStories tokenizer? Com\u0002pare the compression ratio and/or qualitatively describe what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d881be8b",
   "metadata": {},
   "source": [
    "## Exercise 8: Problem (linear): Implementing the linear module (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c7714b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[3, 2] n=6 x∈[-1.725, 0.063] μ=-0.740 σ=0.702 grad ViewBackward0 [[-1.281, -1.725], [-0.531, -0.048], [0.063, -0.920]]\n",
       "tensor([[-1.2815, -1.7247],\n",
       "        [-0.5314, -0.0480],\n",
       "        [ 0.0631, -0.9196]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MyLinear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        weight = torch.empty(in_features, out_features)\n",
    "        sigma = sqrt(2 / (in_features + out_features))\n",
    "        torch.nn.init.trunc_normal_(weight, mean=0, std=sigma, a=-3 * sigma, b=3 * sigma)\n",
    "\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        # output = x @ self.W \n",
    "\n",
    "        # einsum way\n",
    "        output = einsum(x, self.W, \"... j, j k-> ... k\")\n",
    "\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MyLinear(5, 2)\n",
    "\n",
    "batch = torch.randn(3, 5)\n",
    "\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103cee67",
   "metadata": {},
   "source": [
    "## Exercise 9: Problem (embedding): Implement the embedding module (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146775a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[4] i64 x∈[0, 9] μ=4.500 σ=5.196 [0, 9, 0, 9]\n",
      "tensor([0, 9, 0, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor[4, 5] n=20 x∈[-0.856, 1.729] μ=0.398 σ=0.862 grad IndexBackward0\n",
       "tensor([[ 1.1812,  1.3651, -0.2971,  1.7287, -0.2774],\n",
       "        [-0.5769,  0.7990,  0.2255,  0.6847, -0.8557],\n",
       "        [ 1.1812,  1.3651, -0.2971,  1.7287, -0.2774],\n",
       "        [-0.5769,  0.7990,  0.2255,  0.6847, -0.8557]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MyEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        weight = torch.empty(num_embeddings, embedding_dim)\n",
    "        torch.nn.init.trunc_normal_(weight, mean=0, std=1, a=-3, b=3)\n",
    "\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        output = self.W[x]\n",
    "\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MyEmbedding(10, 5)\n",
    "\n",
    "batch = torch.randint(0, 10, (4, ))\n",
    "\n",
    "print(batch.v)\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67df26e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[4] i64 x∈[0, 9] μ=4.500 σ=5.196 [0, 9, 0, 9]\n",
      "tensor([0, 9, 0, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor[4, 5] n=20 x∈[-0.856, 1.729] μ=0.398 σ=0.862 grad IndexBackward0\n",
       "tensor([[ 1.1812,  1.3651, -0.2971,  1.7287, -0.2774],\n",
       "        [-0.5769,  0.7990,  0.2255,  0.6847, -0.8557],\n",
       "        [ 1.1812,  1.3651, -0.2971,  1.7287, -0.2774],\n",
       "        [-0.5769,  0.7990,  0.2255,  0.6847, -0.8557]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        weight = torch.empty(num_embeddings, embedding_dim)\n",
    "        torch.nn.init.trunc_normal_(weight, mean=0, std=1, a=-3, b=3)\n",
    "\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        output = self.W[x]\n",
    "\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MyEmbedding(10, 5)\n",
    "\n",
    "batch = torch.randint(0, 10, (4, ))\n",
    "\n",
    "print(batch.v)\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f610c2d",
   "metadata": {},
   "source": [
    "## Exercise 10: Problem (rmsnorm): Root Mean Square Layer Normalization (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95b8ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 8] n=32 x∈[-1.502, 1.712] μ=0.232 σ=0.988 grad MulBackward0\n",
       "tensor([[ 1.3741,  1.0606,  0.6423, -1.5015,  0.4838, -0.8804, -0.0307, -1.1443],\n",
       "        [-0.7808,  1.7116, -0.4074, -1.4571, -0.7556, -0.5807, -0.7981,  0.7915],\n",
       "        [ 1.6059, -0.1561, -0.4864,  0.4298, -0.7413,  1.0544,  0.7831,  1.6434],\n",
       "        [ 1.4381,  1.4575,  0.6863,  1.5006, -0.2604,  0.0469, -0.2828,  0.9667]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MyRMSNorm(torch.nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-5, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        weight = torch.ones(d_model)\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        output = x.to(torch.float32)\n",
    "        denom = torch.sqrt(output.pow(2).mean(dim=-1, keepdim=True) + self.eps)\n",
    "        output = output / denom\n",
    "        output = output * self.W\n",
    "        output = output.to(self.dtype)\n",
    "        return output\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyRMSNorm(8)\n",
    "\n",
    "batch = torch.randn((4, 8))\n",
    "\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00f6fd",
   "metadata": {},
   "source": [
    "## Exercise 11: Problem (positionwise_feedforward): Implement the position-wise feed-forward network (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b37cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 8] n=32 x∈[-0.278, 1.682] μ=0.360 σ=0.627\n",
       "tensor([[ 1.6820,  1.2131,  0.6405, -0.2286,  0.4501, -0.2783, -0.0211, -0.2685],\n",
       "        [-0.2410,  1.3828, -0.1582, -0.2769, -0.2370, -0.2035, -0.2435,  0.5199],\n",
       "        [ 1.3760, -0.0734, -0.1881,  0.2673, -0.2419,  0.8046,  0.5527,  1.4167],\n",
       "        [ 1.0007,  1.0180,  0.3956,  1.0566, -0.1025,  0.0213, -0.1100,  0.6042]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MySilu(torch.nn.Module):\n",
    "    def __init__(self, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        sigm = torch.sigmoid(x)\n",
    "        output = x * sigm\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MySilu()\n",
    "\n",
    "batch = torch.randn((4, 8))\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de58d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 6] n=24 x∈[-74.395, 109.831] μ=3.797 σ=42.568\n",
       "tensor([[-42.3801,  40.7463, -21.8935, -74.3954, -37.8143,  -8.6413],\n",
       "        [-27.2500,  88.8632,  -8.8330, 109.8314, -22.7258,  37.7100],\n",
       "        [ 49.0109,  16.9329, -37.6880,  20.9207,  39.5458, -37.6875],\n",
       "        [  1.6938,  -1.8043,  -1.4190,  13.6263,  14.5836, -19.7981]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt, ceil\n",
    "from einops import einsum, rearrange\n",
    "\n",
    "# https://arxiv.org/pdf/2002.05202\n",
    "class MySwiGlu(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_ff, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = int(ceil(8*d_model // 3 / 64) * 64)\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.silu = MySilu()\n",
    "        self.w1 = torch.randn((self.d_ff, self.d_model))\n",
    "        self.w2 = torch.randn((self.d_model, self.d_ff))\n",
    "        self.w3 = torch.randn((self.d_ff, self.d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        # o1 = self.silu(x @ self.w1.T)\n",
    "        # o3 = x @ self.w3.T\n",
    "        # gated = o1 * o3\n",
    "        # o = gated @ self.w2.T\n",
    "\n",
    "        # einsum way\n",
    "        o1 = einsum(x, self.w1, \"... d_model, d_ff d_model -> ... d_ff\")\n",
    "        o3 = einsum(x, self.w3, \"... d_model, d_ff d_model -> ... d_ff\")\n",
    "        gated = self.silu(o1) * o3\n",
    "        o = einsum(gated, self.w2, \"... d_ff, d_model d_ff -> ... d_model\")\n",
    "        return o\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MySwiGlu(6, 16)\n",
    "\n",
    "batch = torch.randn((4, 6))\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d0273",
   "metadata": {},
   "source": [
    "## Exercise 12: Problem (rope): Implement RoPE (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914e930",
   "metadata": {},
   "source": [
    "Rotation matrix derivation: https://www.youtube.com/watch?v=EZufiIwwqFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a63e3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 4, 8] n=64 x∈[-2.106, 2.110] μ=-0.066 σ=1.056\n",
       "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
       "          -1.6047],\n",
       "         [-1.7937,  0.2579, -0.2504, -1.4358, -0.7223, -0.5667, -0.7696,\n",
       "           0.7617],\n",
       "         [-0.5383,  1.5598, -0.5748,  0.3320, -0.7795,  1.0629,  0.7974,\n",
       "           1.6822],\n",
       "         [-1.4493, -1.1029,  0.1888,  1.4555, -0.2328,  0.0348, -0.2542,\n",
       "           0.8591]],\n",
       "\n",
       "        [[-1.3847, -0.8712, -0.2234,  1.7174,  0.3189, -0.4245,  0.3057,\n",
       "          -0.7746],\n",
       "         [-1.6794, -0.7727, -0.8154, -0.6860, -1.2953,  2.1099, -1.2342,\n",
       "          -0.4891],\n",
       "         [ 0.9787, -0.5571, -0.0280,  0.5308, -0.5117,  1.1814, -0.8125,\n",
       "          -0.7376],\n",
       "         [ 1.3841, -0.2337, -0.2603,  0.6267, -0.1531,  1.8408, -1.1887,\n",
       "           1.3800]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relearn this!\n",
    "class MyRoPE(torch.nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta = theta\n",
    "        self.d_k = d_k\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.device = device\n",
    "        self.rotation_matrix_table = self.generate_rotation_matrix(theta, d_k, max_seq_len)\n",
    "        self.register_buffer('rotation_matrix', self.rotation_matrix_table, persistent=False)\n",
    "\n",
    "    def generate_rotation_block(self, theta, block_index, seq_pos, d_k):\n",
    "        angle = torch.tensor(seq_pos / (theta ** (2 * block_index / d_k)))\n",
    "        cos = torch.cos(angle)\n",
    "        sin = torch.sin(angle)\n",
    "        rotation_matrix = torch.Tensor([[cos, -sin], [sin, cos]])\n",
    "        return rotation_matrix\n",
    "    \n",
    "    def generate_rotation_matrix(self, theta, d_k, max_seq_len):\n",
    "        rotation_matrix_table = torch.zeros(max_seq_len, d_k, d_k)\n",
    "        for i in range(max_seq_len):\n",
    "            blocks = [self.generate_rotation_block(theta, k, i, d_k) for k in range(d_k // 2)]\n",
    "            rotation_matrix_table[i, :, :] = torch.block_diag(*blocks)\n",
    "        return rotation_matrix_table\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor = None):\n",
    "        *dims, seq_len, d_k = x.shape\n",
    "        if token_positions is None:\n",
    "            token_positions = torch.arange(seq_len, device=x.device)\n",
    "        rotation_matrix = self.rotation_matrix_table[token_positions]\n",
    "        x_rotated = rotation_matrix @ x.unsqueeze(-1)\n",
    "        x_rotated = x_rotated.squeeze(-1)\n",
    "        return x_rotated\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "batch = torch.randn((2, 4, 8))\n",
    "model = MyRoPE(10000, 8, 12)\n",
    "tok_positions = torch.arange(4)\n",
    "output = model(batch, tok_positions)\n",
    "output.v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6a2fc",
   "metadata": {},
   "source": [
    "## Exercise 13: Problem (softmax): Implement softmax (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12f5579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 8] n=32 x∈[0.007, 0.507] μ=0.125 σ=0.119\n",
       "tensor([[0.3971, 0.2558, 0.1423, 0.0070, 0.1139, 0.0168, 0.0554, 0.0116],\n",
       "        [0.0460, 0.5071, 0.0659, 0.0240, 0.0471, 0.0557, 0.0452, 0.2090],\n",
       "        [0.2693, 0.0444, 0.0317, 0.0809, 0.0244, 0.1532, 0.1161, 0.2799],\n",
       "        [0.2011, 0.2046, 0.1031, 0.2126, 0.0444, 0.0584, 0.0435, 0.1323]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MySoftmax(x: torch.Tensor, dim: int):\n",
    "    eps = 1e-8\n",
    "    \n",
    "    # numerical stability at high values of logits\n",
    "    # dim-wise max and not overall max\n",
    "    max = torch.max(x, dim=dim, keepdim=True)[0]\n",
    "    x = x - max\n",
    "\n",
    "    # usual business here\n",
    "    num = torch.exp(x)\n",
    "    denom = torch.exp(x).sum(dim=dim, keepdim=True)\n",
    "    output = num / (denom + eps)\n",
    "    return output\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch = torch.randn((4, 8))\n",
    "output = MySoftmax(batch, -1)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaeb2dd",
   "metadata": {},
   "source": [
    "## Exercise 14: Problem (scaled_dot_product_attention): Implement scaled dot-product attention (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a01b1827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 4, 8] n=64 x∈[-1.408, 2.151] μ=0.076 σ=0.790\n",
       "tensor([[[-0.1561, -0.6953,  0.7203, -0.3861, -0.2114,  2.0479,  2.1509,\n",
       "           1.6704],\n",
       "         [-0.4206, -0.5915,  0.7682, -0.6597, -0.2825,  1.3089,  1.5757,\n",
       "           0.8848],\n",
       "         [-1.4079, -0.8897,  0.9736, -0.5634,  0.2719, -0.5261, -0.4475,\n",
       "           0.4843],\n",
       "         [-0.4120, -0.4365,  0.9151,  0.0516, -0.2064,  0.1070,  0.1036,\n",
       "           0.5917]],\n",
       "\n",
       "        [[ 1.9627, -0.3493, -0.4200, -0.1452, -0.2851, -1.0392,  0.1441,\n",
       "           0.8603],\n",
       "         [ 0.7856, -0.7519,  0.2780, -0.0635, -1.0282, -0.3954,  0.2636,\n",
       "           0.0057],\n",
       "         [-0.1239, -0.6923,  0.7523,  0.5994,  0.5321,  0.0085,  0.7380,\n",
       "          -1.0673],\n",
       "         [ 0.1558, -0.8902,  0.0420, -0.2327, -0.4623, -0.6036,  0.4148,\n",
       "          -0.4519]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def Myscaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    #  ## einsum approach\n",
    "    attn_scores = einsum(Q, K, \"... queries d_k, ... keys d_k -> ... queries keys\")\n",
    "    attn_weights = attn_scores / torch.sqrt(torch.tensor(Q.shape[-1]))\n",
    "\n",
    "    if mask is not None:\n",
    "        attn_weights = attn_weights.masked_fill(mask == 0, -torch.inf)\n",
    "\n",
    "    attn_weights = MySoftmax(attn_weights, dim=-1)\n",
    "    context_vec = einsum(attn_weights, V, \"... queries sl, ... sl d_v -> ... queries d_v\")\n",
    "    return context_vec\n",
    "    \n",
    "torch.manual_seed(420)\n",
    "\n",
    "Q = torch.randn((2, 4, 8))\n",
    "K = torch.randn((2, 4, 8))\n",
    "V = torch.randn((2, 4, 8))\n",
    "\n",
    "# creating a mask\n",
    "mask = torch.randn((2, 4, 4))\n",
    "mask = torch.triu(mask, diagonal=1).to(bool)\n",
    "\n",
    "output = Myscaled_dot_product_attention(Q, K, V, ~mask)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30452c",
   "metadata": {},
   "source": [
    "## Exercise 15: Problem (multihead_self_attention): Implement causal multi-head self-attention (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2441a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 8] n=96 x∈[-37.604, 44.982] μ=1.520 σ=13.757 grad ViewBackward0\n",
       "tensor([[[ 44.9816,  -4.0572,   9.5668,  17.2590, -17.3515, -10.4152,  -7.6936,\n",
       "          -34.4534],\n",
       "         [ 14.4895,   2.1835,  26.0109,  20.7137, -21.6453,   4.8867,  -5.4112,\n",
       "           -2.5018],\n",
       "         [ -1.0056,  -4.4707, -16.1527,   2.4396,  11.6497,   0.6426,  11.3221,\n",
       "           -0.1446],\n",
       "         [  5.1057,  -6.8183, -17.2269,   4.7302,  14.0615,   1.3946,  11.8164,\n",
       "           -8.1424],\n",
       "         [-11.7404,  -3.6162, -10.8130, -17.4299,  11.6551,  -4.4994,  -0.2479,\n",
       "            3.2620],\n",
       "         [-24.8512,   7.8084,  22.2743,   3.1124, -10.6928,  30.2615,   5.8352,\n",
       "           30.7121]],\n",
       "\n",
       "        [[-19.2817,  -1.2965,   6.4948,  -8.5323,   2.0376,   7.6350,   2.2789,\n",
       "           13.9557],\n",
       "         [-37.6042,   6.6201,  10.2247,  -0.6709,   3.2950,  16.9392,   5.3303,\n",
       "           33.0000],\n",
       "         [ -2.9748,  -4.8768,   5.5871,  16.4281,   4.5379, -12.4719,  -1.8378,\n",
       "           -4.0125],\n",
       "         [-21.2404,   0.7599,  29.9460,   9.5963,  -9.8929,   5.2589,  -4.9882,\n",
       "           17.6042],\n",
       "         [ -1.5435,   5.8131,  -6.8222,  -5.0511,   1.0927,   4.3094,   2.0665,\n",
       "            2.2948],\n",
       "         [ -2.6097,   3.5150, -20.3922,  -6.9153,  11.8712,   4.8558,   6.2314,\n",
       "            2.5145]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "from torch.nn import Linear\n",
    "\n",
    "class MyCausalMHA(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, max_seq_len=None, theta=10000, device=None, use_rope=False, token_positions=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_k = int(d_model / num_heads)\n",
    "        self.use_rope = use_rope\n",
    "        self.rope = MyRoPE(theta, self.d_k, max_seq_len) if use_rope else None\n",
    "        self.token_positions = token_positions\n",
    "\n",
    "        self.q_proj = Linear(d_model, d_model)\n",
    "        self.k_proj = Linear(d_model, d_model)\n",
    "        self.v_proj = Linear(d_model, d_model)\n",
    "        self.o_proj = Linear(d_model, d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, sl, d_model = x.shape\n",
    "\n",
    "        # queries = einsum(x, self.q_proj.weight, \"... sl d_m, d_m d_m -> ... sl d_m\")\n",
    "        # keys = einsum(x, self.k_proj.weight, \"... sl d_m, d_m d_m -> ... sl d_m\")\n",
    "        # values = einsum(x, self.v_proj.weight, \"... sl d_m, d_m d_m -> ... sl d_m\")\n",
    "\n",
    "        queries = self.q_proj(x)\n",
    "        keys = self.k_proj(x)\n",
    "        values = self.v_proj(x)\n",
    "\n",
    "        # Expand the head dimension into it's own dimension and transpose for self-attention soon\n",
    "        queries = rearrange(queries, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        keys = rearrange(keys, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        values = rearrange(values, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "\n",
    "        # use rope if needed\n",
    "        if self.use_rope:\n",
    "            queries = self.rope(queries, self.token_positions)\n",
    "            keys = self.rope(keys, self.token_positions)\n",
    "\n",
    "        # apply causal mask``\n",
    "        causal_mask = torch.ones((sl, sl))\n",
    "        causal_mask = torch.triu(causal_mask, diagonal=1).to(bool)\n",
    "        context_vec = Myscaled_dot_product_attention(queries, keys, values, ~causal_mask)\n",
    "\n",
    "        # concatenate head with o_projection & pass it through o_proj\n",
    "        context_vec = rearrange(context_vec, \"... h sl d_v -> ... sl (h d_v)\")\n",
    "        # output = einsum(context_vec, self.o_proj, \"... sl d_model, d_model d_v -> ... sl d_v\")\n",
    "        output = self.o_proj(context_vec)\n",
    "        return output\n",
    "\n",
    "    \n",
    "\n",
    "torch.manual_seed(42)\n",
    "m = torch.randn(8, 8)\n",
    "model = MyCausalMHA(d_model=8, num_heads=2, max_seq_len=10, use_rope=False)\n",
    "model.q_proj.weight.data.copy_(m)\n",
    "model.k_proj.weight.data.copy_(m)\n",
    "model.v_proj.weight.data.copy_(m)\n",
    "model.o_proj.weight.data.copy_(m)\n",
    "\n",
    "model.q_proj.bias.data.zero_()\n",
    "model.k_proj.bias.data.zero_()\n",
    "model.v_proj.bias.data.zero_()\n",
    "model.o_proj.bias.data.zero_()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "batch = torch.randn((2, 6, 8))\n",
    "context_vec1 = model(batch)\n",
    "context_vec1.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc26356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 8] n=96 x∈[-37.604, 44.982] μ=1.520 σ=13.757\n",
       "tensor([[[ 44.9816,  -4.0572,   9.5668,  17.2590, -17.3515, -10.4152,  -7.6936,\n",
       "          -34.4534],\n",
       "         [ 14.4895,   2.1835,  26.0109,  20.7137, -21.6453,   4.8867,  -5.4112,\n",
       "           -2.5018],\n",
       "         [ -1.0056,  -4.4707, -16.1527,   2.4396,  11.6497,   0.6426,  11.3221,\n",
       "           -0.1446],\n",
       "         [  5.1057,  -6.8183, -17.2269,   4.7302,  14.0615,   1.3946,  11.8164,\n",
       "           -8.1424],\n",
       "         [-11.7404,  -3.6162, -10.8130, -17.4299,  11.6551,  -4.4994,  -0.2479,\n",
       "            3.2620],\n",
       "         [-24.8512,   7.8084,  22.2743,   3.1124, -10.6928,  30.2615,   5.8352,\n",
       "           30.7121]],\n",
       "\n",
       "        [[-19.2817,  -1.2965,   6.4948,  -8.5323,   2.0376,   7.6350,   2.2789,\n",
       "           13.9557],\n",
       "         [-37.6042,   6.6201,  10.2247,  -0.6709,   3.2950,  16.9392,   5.3303,\n",
       "           33.0000],\n",
       "         [ -2.9748,  -4.8768,   5.5871,  16.4281,   4.5379, -12.4719,  -1.8378,\n",
       "           -4.0125],\n",
       "         [-21.2404,   0.7599,  29.9460,   9.5963,  -9.8929,   5.2589,  -4.9882,\n",
       "           17.6042],\n",
       "         [ -1.5435,   5.8131,  -6.8222,  -5.0511,   1.0927,   4.3094,   2.0665,\n",
       "            2.2948],\n",
       "         [ -2.6097,   3.5150, -20.3922,  -6.9153,  11.8712,   4.8558,   6.2314,\n",
       "            2.5145]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCausalMHA2(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, max_seq_len=None, theta=10000, device=None, use_rope=False, token_positions=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_k = int(d_model / num_heads)\n",
    "        self.use_rope = use_rope\n",
    "        self.rope = MyRoPE(theta, self.d_k, max_seq_len) if use_rope else None\n",
    "        self.token_positions = token_positions\n",
    "\n",
    "        self.q_proj = torch.randn(d_model, d_model)\n",
    "        self.k_proj = torch.randn(d_model, d_model)\n",
    "        self.v_proj = torch.randn(d_model, d_model)\n",
    "        self.o_proj = torch.randn(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, sl, d_model = x.shape\n",
    "\n",
    "        # einsum notation\n",
    "        queries = einsum(x, self.q_proj, \"... sl d_m, d_k d_m -> ... sl d_k\")\n",
    "        keys = einsum(x, self.k_proj, \"... sl d_m, d_k d_m -> ... sl d_k\")\n",
    "        values = einsum(x, self.v_proj, \"... sl d_m, d_k d_m -> ... sl d_k\")\n",
    "\n",
    "        # pytorch matrix notation\n",
    "        # CAREFUL: be very careful with transposing as PyTorch stores linear layers in (out_features, in_features) form\n",
    "        # queries = x @ self.q_proj.T\n",
    "        # keys = x @ self.k_proj.T\n",
    "        # values = x @ self.v_proj.T\n",
    "\n",
    "        # Expand the head dimension into it's own dimension and transpose for self-attention soon\n",
    "        queries = rearrange(queries, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        keys = rearrange(keys, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        values = rearrange(values, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "\n",
    "        # use rope if needed\n",
    "        if self.use_rope:\n",
    "            queries = self.rope(queries, self.token_positions)\n",
    "            keys = self.rope(keys, self.token_positions)\n",
    "\n",
    "        # apply causal mask\n",
    "        causal_mask = torch.ones((sl, sl))\n",
    "        causal_mask = torch.triu(causal_mask, diagonal=1).to(bool)\n",
    "        context_vec = Myscaled_dot_product_attention(queries, keys, values, ~causal_mask) # CAREFUL: causal_mask should not attend to future tokens\n",
    "\n",
    "        # concatenate head with o_projection & pass it through o_proj\n",
    "        context_vec = rearrange(context_vec, \"... h sl d_v -> ... sl (h d_v)\")\n",
    "        output = einsum(context_vec, self.o_proj, \"... sl d_model, d_v d_model -> ... sl d_v\")\n",
    "        # output = context_vec @ self.o_proj.T\n",
    "        return output\n",
    "    \n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyCausalMHA2(d_model=8, num_heads=2, max_seq_len=10, use_rope=False)\n",
    "model.q_proj.data.copy_(m)\n",
    "model.k_proj.data.copy_(m)\n",
    "model.v_proj.data.copy_(m)\n",
    "model.o_proj.data.copy_(m)\n",
    "\n",
    "context_vec2 = model(batch)\n",
    "context_vec2.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e21d85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(context_vec1, context_vec2, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a05c75",
   "metadata": {},
   "source": [
    "## Exercise 16: Problem (transformer_block): Implement the Transformer block (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d894ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 8] n=96 x∈[-131.735, 125.800] μ=-0.974 σ=53.200 grad AddBackward0\n",
       "tensor([[[ -30.6578,   33.7612,   35.9949,  -13.0006, -113.8567,   44.8295,\n",
       "            94.9931,  -44.8292],\n",
       "         [ -34.0975,   51.0059,   41.1780,  -19.0532,  -78.3312,   31.9316,\n",
       "            57.9824,  -17.0674],\n",
       "         [ -72.8474, -131.7351,  -25.1189,  -12.0696,   11.0075,   16.2014,\n",
       "            44.7393,  -32.0036],\n",
       "         [ -38.0562,  -36.5616,   36.2781,    8.6351,  -61.7301,   39.3872,\n",
       "            76.6221,  -36.4891],\n",
       "         [ -18.7337,  -31.8101,   13.3985,  -25.0176,  -11.5342,   33.5430,\n",
       "            60.6820,  -36.9917],\n",
       "         [  29.1150,   28.7488,  -55.5202,  -41.5676,   31.3636,   41.8333,\n",
       "            34.3643,  -23.0237]],\n",
       "\n",
       "        [[  -5.0573,  125.7999,   20.2271,  -59.8220, -107.2766,   68.2812,\n",
       "            47.9998,  -14.3731],\n",
       "         [ -61.9032,  -57.3246,  -19.4308,    5.0884,   -2.7076,   21.9048,\n",
       "             2.9424,   33.5769],\n",
       "         [ -24.3774,  -10.0657,   42.8495,   60.4710,  -46.1791,  -40.8142,\n",
       "           -48.5564,  -13.8084],\n",
       "         [  70.8347,   27.2074,   68.1606,   94.7534,  -72.5252,  -16.0102,\n",
       "           -68.7625,   56.5744],\n",
       "         [ -25.6330,  -40.5323,   -2.3343,   44.2679,  -26.8085,   44.6750,\n",
       "            24.2750,  -19.5150],\n",
       "         [  14.8456,   50.5467,  -92.5855, -116.6030,  -13.9043,  101.9974,\n",
       "           121.9304,  -91.6963]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyTransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, d_ff: int, max_seq_len=10000, theta=10000, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.device = device\n",
    "        self.attn = MyCausalMHA2(d_model=d_model, num_heads=num_heads, max_seq_len=max_seq_len, theta=theta, use_rope=True, device=device)\n",
    "        self.ffn = MySwiGlu(d_model=d_model, d_ff=d_ff, device=device, dtype=dtype)\n",
    "        self.attnorm = MyRMSNorm(d_model=d_model, device=device, dtype=dtype)\n",
    "        self.ffnnorm = MyRMSNorm(d_model=d_model, device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        bs, sl, d_model = x.shape\n",
    "\n",
    "        x_norm = self.attnorm(x)\n",
    "        x_attn = self.attn(x_norm)\n",
    "        x_add = x + x_attn\n",
    "\n",
    "        x_ffn_norm = self.ffnnorm(x_add)\n",
    "        x_ffn = self.ffn(x_ffn_norm)\n",
    "        x_final = x_add + x_ffn\n",
    "        return x_final\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyTransformerBlock(d_model=8, num_heads=2, d_ff=64, max_seq_len=1000)\n",
    "\n",
    "batch = torch.randn((2, 6, 8))\n",
    "context_vec = model(batch)\n",
    "context_vec.v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f4fb6",
   "metadata": {},
   "source": [
    "## Exercise 17: Problem (transformer_lm): Implementing the Transformer LM (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9ddf79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 30, 32] n=1920 (7.5Kb) x∈[-2.094, 1.670] μ=-0.089 σ=0.636 grad ViewBackward0\n",
       "tensor([[[-0.2248, -1.1190,  0.3314,  ..., -0.2760, -0.6265,  1.1214],\n",
       "         [-0.5788, -0.2246, -0.9277,  ...,  1.1431,  0.4534,  0.0186],\n",
       "         [-0.7878, -0.4018, -1.0746,  ...,  1.3445,  0.0768,  0.1375],\n",
       "         ...,\n",
       "         [-0.4958, -0.4019, -0.8402,  ...,  0.7856, -0.2178,  0.4958],\n",
       "         [-0.0602,  0.7938, -0.6014,  ...,  1.2430, -0.3639,  0.0959],\n",
       "         [ 0.2141,  0.7943, -0.4072,  ...,  1.5604, -0.6140,  0.3407]],\n",
       "\n",
       "        [[ 0.4441, -0.1686, -0.6878,  ..., -1.2776,  0.2949, -0.2075],\n",
       "         [ 0.7333,  0.4126, -0.1541,  ..., -0.0763, -0.3868,  0.3773],\n",
       "         [ 0.6944,  0.4951,  0.2128,  ...,  0.5993, -0.6893,  0.6861],\n",
       "         ...,\n",
       "         [-0.3769,  0.5701, -0.2447,  ..., -0.0607,  0.9560, -1.2039],\n",
       "         [ 1.4656, -0.7442, -0.0486,  ..., -0.4798, -0.2522,  0.5383],\n",
       "         [ 1.2855,  0.7979,  0.4193,  ..., -0.9699, -0.7889,  0.2751]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyTransformerLM(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, context_length, d_model, num_layers, num_heads, d_ff, rope_theta=10000, device=None):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_length = context_length\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.rope_theta = rope_theta\n",
    "        self.device = device\n",
    "        self.tokembedding = MyEmbedding(num_embeddings=vocab_size, embedding_dim=d_model, device=device)\n",
    "        self.layers = [MyTransformerBlock(d_model=d_model, num_heads=num_heads, d_ff=d_ff, max_seq_len=context_length, theta=rope_theta) for _ in range(self.num_layers)]\n",
    "        self.norm = MyRMSNorm(d_model=d_model, eps=1e-5, device=device)\n",
    "        self.linear = MyLinear(d_model, vocab_size, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokembedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) # CAREFUL: these are layers and not heads\n",
    "        x = self.norm(x)\n",
    "        x = self.linear(x)\n",
    "        # x = MySoftmax(x, -1) # commenting as the unit test expects us to return unnormalized logits\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyTransformerLM(vocab_size=32, context_length = 1024, d_model=8, num_layers=3, num_heads=2, d_ff=64, rope_theta=10000)\n",
    "\n",
    "batch = torch.randn((2, 6, 8))\n",
    "batch = torch.randint(0, 32, (2, 30, ))\n",
    "context_vec = model(batch)\n",
    "context_vec.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2720690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d6069a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.W.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c057509",
   "metadata": {},
   "source": [
    "Number of parameters\n",
    "\n",
    "\n",
    "* 1. tokembedding\n",
    "\n",
    "\n",
    "vocab_size * d_model = 32 * 8 = 256\n",
    "\n",
    "code:\n",
    "`model.tokembedding.W.numel()`\n",
    "\n",
    "---\n",
    "\n",
    "* 2. attns:\n",
    "attn -> num_layers * (q_proj + k_proj + v_proj + o_proj) = num_layers * (d_model ** 2 * 4) = 3 * 8**2 * 4 = 768\n",
    "\n",
    "code:\n",
    "`model.attns[0].attn.q_proj.numel() * 4 * num_layers`\n",
    "\n",
    "ffn -> num_layers * (w1 + w2 + w3) = num_layers * (d_ff * d_model * 3) = 3 * 64 * 8 * 3 = 4608\n",
    "\n",
    "code:\n",
    "`model.attns[0].ffn.w1.numel() * 3 * num_layers`\n",
    "\n",
    "attnorm -> num_layers * d_model = 3 * 8 = 24\n",
    "\n",
    "code:\n",
    "`model.attns[0].attnorm.W.numel()`\n",
    "\n",
    "ffnnorm -> num_layers * d_model = 3 * 8 = 24\n",
    "\n",
    "code:\n",
    "`model.attns[0].ffnnorm.W.numel()`\n",
    "\n",
    "---\n",
    "\n",
    "3. norm -> d_model = 8\n",
    "\n",
    "code:\n",
    "`model.norm.W.numel()`\n",
    "\n",
    "4. linear -> d_model * vocab_size = 8 * 32 = 2048\n",
    "\n",
    "code:\n",
    "`model.linear.W.numel()`\n",
    "\n",
    "Total = 256 + 768 + 4608 + 24 + 24 + 8 + 2048 = 48736 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea677c3",
   "metadata": {},
   "source": [
    "## Exercise 18: Problem (transformer_accounting): Transformer LM resource accounting (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e386205",
   "metadata": {},
   "source": [
    "(a) Consider GPT-2 XL, which has the following configuration:\n",
    "```\n",
    "vocab_size : 50,257\n",
    "context_length : 1,024\n",
    "num_layers : 48\n",
    "d_model : 1,600\n",
    "num_heads : 25\n",
    "d_ff : 6,400\n",
    "```\n",
    "Suppose we constructed our model using this configuration. How many trainable parameters\n",
    "would our model have? Assuming each parameter is represented using single-precision floating\n",
    "point, how much memory is required to just load this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b28163c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637945600"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_param_count(vocab_size, context_length, num_layers, d_model, num_heads, d_ff):\n",
    "    # embedding\n",
    "    emb_params = vocab_size * d_model\n",
    "    emb_params += context_length * d_model # position embedding\n",
    "\n",
    "    # attention\n",
    "    attn_params = num_layers * (d_model ** 2 * 4)\n",
    "\n",
    "    # norm\n",
    "    attnorm_params = num_layers * d_model * 2 # for bias\n",
    "    ffnnorm_params =  num_layers * d_model * 2 # for bias\n",
    "    finalnorm_params = d_model * 2 # for weight and bias\n",
    "    norm_params = attnorm_params + ffnnorm_params + finalnorm_params\n",
    "\n",
    "    # MLP/linear\n",
    "    ffn_params =  num_layers * (d_ff * d_model * 2 + d_ff * 2) # for gpt2xl\n",
    "\n",
    "    # output projection\n",
    "    output_params = d_model * vocab_size\n",
    "\n",
    "    params = {\"emb_params\": emb_params,\n",
    "                    \"attn_params\": attn_params,\n",
    "                    \"ffn_params\": ffn_params,\n",
    "                    \"norm_params\": norm_params,\n",
    "                    \"output_params\": output_params}\n",
    "    return params\n",
    "\n",
    "params = get_param_count(vocab_size=50257, context_length=1024, num_layers=48, d_model=1600, num_heads=25, d_ff=6400)\n",
    "sum(params.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828c709",
   "metadata": {},
   "source": [
    "The total number of parameters in GPT2-XL are 1.64B parameters.\n",
    "\n",
    "Here is the split across layers.\n",
    "\n",
    "```\n",
    "{'emb_params': 82049600,\n",
    " 'attn_params': 491520000,\n",
    " 'ffn_params': 983654400,\n",
    " 'norm_params': 310400,\n",
    " 'output_params': 80411200}\n",
    "```\n",
    "\n",
    "CAREFUL: Note that GPT2-XL does not use SwiGLU feed forward layers. Hence, the MLP/linear layer param count is much lesser than the architecture we used earlier.\n",
    "\n",
    "In terms of memory, as each parameter is stored as a single precision floating point, i.e. float32 or FP32, the memory needed to hold these weights in memory will be ~1.64B * 4 bytes. = 6.56GB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062d905",
   "metadata": {},
   "source": [
    "b) Identify the matrix multiplies required to complete a forward pass of our GPT-2 XL-shaped\n",
    "model. How many FLOPs do these matrix multiplies require in total? Assume that our input\n",
    "sequence has context_length tokens.\n",
    "Deliverable: A list of matrix multiplies (with descriptions), and the total number of FLOPs\n",
    "required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee55851",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce609837",
   "metadata": {},
   "source": [
    "1. Embedding module just indexes and fetches the embedding vector for each token. Hence, no matrix multiplies.\n",
    "2. For RMSNorm module, here are the flop calculations.:\n",
    "* For each sequence position (1bs and 1sl), we have a hidden_dim vector for which the square operation is `hidden_dim` flops.\n",
    "* Sum is `hidden_dim-1` flops.\n",
    "* Division for mean calculation is 1 flop\n",
    "* sqrt is 1 flop\n",
    "* eps addition is 1 flop\n",
    "* Division by RMS is `hidden_dim` flops\n",
    "* Total flops for one sequence position is 3 * hidden_dim + 2 == `3 * hidden_dim`\n",
    "* Total flops for RMSNorm are `3 * hidden_dim * seq_len * batch_size`.\n",
    "3. For each transformer block,\n",
    "* RMSNorm is `3 * batch_size * seq_len * hidden_dim` computations\n",
    "* FFNNorm is the same as above.\n",
    "* 2 residual connections sum upto `2 * batch_size * seq_len * hidden_dim`\n",
    "* What is remaining is the causal attention block and position wise FFN - `(4 * seq_len**2 * hidden_dim + 4 * seq_len * d_model * hidden_dim) * n_heads`\n",
    "* So, for all transformer blocks, number of flops are `num_layers * ()`\n",
    "4. For the linear layer, the flop count is `2 * batch_size * seq_len * hidden_dim * vocab_size`\n",
    "\n",
    "# Codifying this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d48fd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emb_flops': 0, 'attn_flops': 1332530380800, 'ffn_flops': 2013265920000, 'norm_flops': 476774400, 'output_flops': 164682137600, 'residual_flops': 157286400}\n",
      "Total flops: 3511B flops\n"
     ]
    }
   ],
   "source": [
    "def get_flop_count(vocab_size, context_length, num_layers, d_model, num_heads, d_ff, batch_size):\n",
    "    # embedding\n",
    "    emb_flops = 0\n",
    "\n",
    "    # attention\n",
    "    d_k = d_model // num_heads\n",
    "    qkv_proj_flops = 3 * 2 * batch_size * context_length * d_model * d_model # 2mnp formula\n",
    "    qk_flops = num_heads * 2 * batch_size * context_length * context_length * d_k\n",
    "    softmax_flops = num_heads * 3 * batch_size * context_length * context_length # approx 3 ops per element * number of heads\n",
    "    attn_v_flops = num_heads * 2 * batch_size * context_length * context_length * d_k\n",
    "    o_proj_flops = 2 * batch_size * context_length * d_model * d_model\n",
    "\n",
    "    attn_flops_each_layer = qkv_proj_flops + qk_flops + softmax_flops + attn_v_flops + o_proj_flops\n",
    "    attn_flops = num_layers * attn_flops_each_layer\n",
    "\n",
    "    # rms norm (3 per layer, attn_norm, ffn_norm, final_norm)\n",
    "    norm_flops_per_layer = 3 * batch_size * context_length * d_model # CAREFUL: calculation for each layer\n",
    "    norm_flops = (2 * num_layers + 1) * norm_flops_per_layer\n",
    "\n",
    "    # MLP/linear\n",
    "    # CAREFUL: GPT-2 uses standard FFN and not SwiGLU. So, just 2 matrix multiplies\n",
    "    ffn_flops = 2 * batch_size * context_length * d_model * d_ff + \\\n",
    "                2 * batch_size * context_length * d_ff * d_model\n",
    "    \n",
    "    ffn_flops = num_layers * ffn_flops\n",
    "    # ffn_params =  num_layers * (d_ff * d_model * 2 + d_ff * 2) # for gpt2xl\n",
    "\n",
    "    # output projection\n",
    "    output_flops = 2 * batch_size * context_length * d_model * vocab_size\n",
    "    # output_params = d_model * vocab_size\n",
    "\n",
    "    # residual connections\n",
    "    residual_flops = 2 * batch_size * context_length * d_model * num_layers # CAREFUL: 2 residuals per layer\n",
    "\n",
    "    flops = {\"emb_flops\": emb_flops,\n",
    "            \"attn_flops\": attn_flops,\n",
    "            \"ffn_flops\": ffn_flops,\n",
    "            \"norm_flops\": norm_flops,\n",
    "            \"output_flops\": output_flops,\n",
    "            \"residual_flops\": residual_flops}\n",
    "    return flops\n",
    "\n",
    "flops = get_flop_count(vocab_size=50257, context_length=1024, num_layers=48, d_model=1600, num_heads=25, d_ff=6400, batch_size=1)\n",
    "print(flops)\n",
    "print(f\"Total flops: {round(sum(flops.values()) / 1e9)}B flops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "686f6038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "emb_flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "attn_flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ffn_flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "norm_flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "residual_flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total Flops",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Attention FLOP %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FFN FLOP %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b526a650-0253-4fba-98c8-2c7a6b200645",
       "rows": [
        [
         "0",
         "gpt2_small",
         "0",
         "97089748992",
         "241591910400",
         "58982400",
         "79047426048",
         "18874368",
         "417806942208",
         "23.2",
         "76.7"
        ],
        [
         "1",
         "gpt2_medium",
         "0",
         "310445604864",
         "644245094400",
         "154140672",
         "105396568064",
         "50331648",
         "1060291739648",
         "29.3",
         "70.7"
        ],
        [
         "2",
         "gpt2_large",
         "0",
         "678722273280",
         "1207959552000",
         "287047680",
         "131745710080",
         "94371840",
         "2018808954880",
         "33.6",
         "66.4"
        ],
        [
         "3",
         "gpt2_xl_sl1k",
         "0",
         "1332530380800",
         "2013265920000",
         "476774400",
         "164682137600",
         "157286400",
         "3511112499200",
         "38.0",
         "62.0"
        ],
        [
         "4",
         "gpt2_xl_sl16k",
         "0",
         "99535867084800",
         "32212254720000",
         "7628390400",
         "2634914201600",
         "2516582400",
         "134393180979200",
         "74.1",
         "25.9"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>emb_flops</th>\n",
       "      <th>attn_flops</th>\n",
       "      <th>ffn_flops</th>\n",
       "      <th>norm_flops</th>\n",
       "      <th>output_flops</th>\n",
       "      <th>residual_flops</th>\n",
       "      <th>Total Flops</th>\n",
       "      <th>Attention FLOP %</th>\n",
       "      <th>FFN FLOP %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2_small</td>\n",
       "      <td>0</td>\n",
       "      <td>97089748992</td>\n",
       "      <td>241591910400</td>\n",
       "      <td>58982400</td>\n",
       "      <td>79047426048</td>\n",
       "      <td>18874368</td>\n",
       "      <td>417806942208</td>\n",
       "      <td>23.2</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2_medium</td>\n",
       "      <td>0</td>\n",
       "      <td>310445604864</td>\n",
       "      <td>644245094400</td>\n",
       "      <td>154140672</td>\n",
       "      <td>105396568064</td>\n",
       "      <td>50331648</td>\n",
       "      <td>1060291739648</td>\n",
       "      <td>29.3</td>\n",
       "      <td>70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2_large</td>\n",
       "      <td>0</td>\n",
       "      <td>678722273280</td>\n",
       "      <td>1207959552000</td>\n",
       "      <td>287047680</td>\n",
       "      <td>131745710080</td>\n",
       "      <td>94371840</td>\n",
       "      <td>2018808954880</td>\n",
       "      <td>33.6</td>\n",
       "      <td>66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2_xl_sl1k</td>\n",
       "      <td>0</td>\n",
       "      <td>1332530380800</td>\n",
       "      <td>2013265920000</td>\n",
       "      <td>476774400</td>\n",
       "      <td>164682137600</td>\n",
       "      <td>157286400</td>\n",
       "      <td>3511112499200</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2_xl_sl16k</td>\n",
       "      <td>0</td>\n",
       "      <td>99535867084800</td>\n",
       "      <td>32212254720000</td>\n",
       "      <td>7628390400</td>\n",
       "      <td>2634914201600</td>\n",
       "      <td>2516582400</td>\n",
       "      <td>134393180979200</td>\n",
       "      <td>74.1</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  emb_flops      attn_flops       ffn_flops  norm_flops  \\\n",
       "0     gpt2_small          0     97089748992    241591910400    58982400   \n",
       "1    gpt2_medium          0    310445604864    644245094400   154140672   \n",
       "2     gpt2_large          0    678722273280   1207959552000   287047680   \n",
       "3   gpt2_xl_sl1k          0   1332530380800   2013265920000   476774400   \n",
       "4  gpt2_xl_sl16k          0  99535867084800  32212254720000  7628390400   \n",
       "\n",
       "    output_flops  residual_flops      Total Flops  Attention FLOP %  \\\n",
       "0    79047426048        18874368     417806942208              23.2   \n",
       "1   105396568064        50331648    1060291739648              29.3   \n",
       "2   131745710080        94371840    2018808954880              33.6   \n",
       "3   164682137600       157286400    3511112499200              38.0   \n",
       "4  2634914201600      2516582400  134393180979200              74.1   \n",
       "\n",
       "   FFN FLOP %  \n",
       "0        76.7  \n",
       "1        70.7  \n",
       "2        66.4  \n",
       "3        62.0  \n",
       "4        25.9  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gpt2_configs = [\n",
    "    {\n",
    "        \"name\": \"gpt2_small\",\n",
    "        \"num_layers\": 12,\n",
    "        \"d_model\": 768,\n",
    "        \"num_heads\": 12,\n",
    "        \"batch_size\": 1,\n",
    "        \"context_length\": 1024,\n",
    "        \"vocab_size\": 50257,\n",
    "        \"d_ff\": 6400\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gpt2_medium\",\n",
    "        \"num_layers\": 24,\n",
    "        \"d_model\": 1024,\n",
    "        \"num_heads\": 16,\n",
    "        \"batch_size\": 1,\n",
    "        \"context_length\": 1024,\n",
    "        \"vocab_size\": 50257,\n",
    "        \"d_ff\": 6400\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gpt2_large\",\n",
    "        \"num_layers\": 36,\n",
    "        \"d_model\": 1280,\n",
    "        \"num_heads\": 20,\n",
    "        \"batch_size\": 1,\n",
    "        \"context_length\": 1024,\n",
    "        \"vocab_size\": 50257,\n",
    "        \"d_ff\": 6400\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gpt2_xl_sl1k\",\n",
    "        \"num_layers\": 48,\n",
    "        \"d_model\": 1600,\n",
    "        \"num_heads\": 25,\n",
    "        \"batch_size\": 1,\n",
    "        \"context_length\": 1024,\n",
    "        \"vocab_size\": 50257,\n",
    "        \"d_ff\": 6400\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"gpt2_xl_sl16k\",\n",
    "        \"num_layers\": 48,\n",
    "        \"d_model\": 1600,\n",
    "        \"num_heads\": 25,\n",
    "        \"batch_size\": 1,\n",
    "        \"context_length\": 16384,\n",
    "        \"vocab_size\": 50257,\n",
    "        \"d_ff\": 6400\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for config in gpt2_configs:\n",
    "    flops = {}\n",
    "    flops['model'] = config['name']\n",
    "    config_args = {k: v for k, v in config.items() if k != 'name'}\n",
    "    flop_counts = get_flop_count(**config_args)\n",
    "    flops.update(flop_counts)\n",
    "    flops['Total Flops'] = int(sum(flop_counts.values()))\n",
    "    flops['Attention FLOP %'] = round(flops['attn_flops'] * 100 / flops['Total Flops'], 1)\n",
    "    flops['FFN FLOP %'] = round((flops['ffn_flops'] + flops['output_flops']) * 100 / flops['Total Flops'], 1)\n",
    "    results.append(flops)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c881dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREFUL\n",
    "# Rearrange operations are flop free! They do not consume flops.\n",
    "# No mathematical operations are happening at this time. Memory layout is changing.\n",
    "# Some of the other operations that are FLOP-free are view, stack, cat, squeeze, unsqueeze, transpose, permute, reshape etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a0119cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Based on your analysis above, which parts of the model require the most FLOPs\n",
    "# Answer: FFN layers require the most FLOPS at all model scales. This is where a lot of compute time is being spent.\n",
    "\n",
    "# (d) Repeat your analysis with GPT-2 small (12 layers, 768 d_model, 12 heads), GPT-2 medium (24\n",
    "# layers, 1024 d_model, 16 heads), and GPT-2 large (36 layers, 1280 d_model, 20 heads). As the\n",
    "# model size increases, which parts of the Transformer LM take up proportionally more or less of\n",
    "# the total FLOPs?\n",
    "# Deliverable: For each model, provide a breakdown of model components and its associated\n",
    "# FLOPs (as a proportion of the total FLOPs required for a forward pass). In addition, provide a\n",
    "# one-to-two sentence description of how varying the model size changes the proportional FLOPs\n",
    "# of each component.\n",
    "\n",
    "# Answer: The above table provides the breakdown of FLOP% across attention and FFN layers as the model size increases. A few insights:\n",
    "# 1. At low model sizes, the attention flops is around 30% of total FLOPS.\n",
    "# 2. As context length grows, attention flops % significantly goes up and slowing down the inference.\n",
    "\n",
    "# (e) Take GPT-2 XL and increase the context length to 16,384. How does the total FLOPs for one\n",
    "# forward pass change? How do the relative contribution of FLOPs of the model components\n",
    "# change\n",
    "# As GPT-2 XL model observes a context length increase from 1k to 16k, the attention flops go up \n",
    "# from occupying 40% of total flops to 75% of total flops!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0468d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ptflops import get_model_complexity_info\n",
    "\n",
    "# layer = MyRMSNorm(d_model=8)\n",
    "# torch.manual_seed(42)\n",
    "# batch = torch.randn(2, 4, 8)\n",
    "\n",
    "# macs, params = get_model_complexity_info(layer, tuple(batch.shape), print_per_layer_stat=True, verbose=True)\n",
    "# print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "# print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d889dafe",
   "metadata": {},
   "source": [
    "## Exercise 19: Problem (cross_entropy): Implement Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e0d4d3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8959376811981201"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def MyCrossEntropy(logits, targs):\n",
    "    eps = 1e-8\n",
    "    probs = MySoftmax(logits, -1)\n",
    "    targs_onehot = F.one_hot(targs)\n",
    "    loss = - (targs_onehot * (probs + eps).log()).sum(-1)\n",
    "    return loss.mean()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# logits = torch.randn(4, 3)\n",
    "# targs = torch.randint(0, 3, (4,))\n",
    "\n",
    "logits = torch.randn(2, 4, 3)\n",
    "targs = torch.randint(0, 3, (2, 4,))\n",
    "\n",
    "loss = MyCrossEntropy(logits, targs)\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a84ae725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor 1.896"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn(rearrange(logits, \"b s d -> (b s) d\"), rearrange(targs, \"b s -> (b s)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6d3d52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8959378004074097 1.8959379196166992\n"
     ]
    }
   ],
   "source": [
    "def MySoftmax(x: torch.Tensor, dim: int):\n",
    "    eps = 1e-8\n",
    "    \n",
    "    # numerical stability at high values of logits\n",
    "    # dim-wise max and not overall max\n",
    "    max = torch.max(x, dim=dim, keepdim=True)[0]\n",
    "    x = x - max\n",
    "\n",
    "    # usual business here\n",
    "    num = torch.exp(x)\n",
    "    denom = torch.exp(x).sum(dim=dim, keepdim=True)\n",
    "    output = num / (denom + eps)\n",
    "    return output\n",
    "\n",
    "def MyLogSoftmax(x, dim):\n",
    "    # log_softmax is equal to log(softmax values)\n",
    "    # log(softmax values) = log(num / denom) = log(num) - log(denom)\n",
    "    # log(num) = log(torch.exp(x)) = x # cancel log and exp\n",
    "    # log(denom) = log(torch.exp(x).sum(dim, keepdim=True))\n",
    "    # log_softmax = x - log(torch.exp(x).sum(dim, keepdim=True))\n",
    "\n",
    "    eps = 1e-8\n",
    "    max = torch.max(x, dim, keepdim=True)[0]\n",
    "    x_shifted = x - max\n",
    "\n",
    "    output = x_shifted - torch.log(torch.exp(x_shifted).sum(dim=dim, keepdim=True))\n",
    "    return output\n",
    "\n",
    "\n",
    "def MyCrossEntropy(logits, targs):\n",
    "    eps = 1e-8\n",
    "    # probs = MySoftmax(logits, -1) # torch.exp might create issues here. Instead, consider log_softmax.\n",
    "    # probs = torch.log_softmax(logits, -1)\n",
    "    probs = MyLogSoftmax(logits, -1)\n",
    "    num_classes = logits.shape[-1]\n",
    "    targs_onehot = F.one_hot(targs, num_classes=num_classes) # CAREFUL: Assign num_classes. Otherwise, absence of a class in target might not yield enough classes.\n",
    "    loss = - (targs_onehot * (probs)).sum(-1)\n",
    "    return loss.mean()\n",
    "\n",
    "loss1 = MyCrossEntropy(logits, targs)\n",
    "loss1.item()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss2 = loss_fn(rearrange(logits, \"b s d -> (b s) d\"), rearrange(targs, \"b d -> (b d)\"))\n",
    "\n",
    "print(loss1.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "70cd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def printt(*args):\n",
    "    frame = inspect.currentframe().f_back\n",
    "    names = {id(v): k for k, v in frame.f_locals.items()}\n",
    "    for arg in args:\n",
    "        var_name = names.get(id(arg), None)\n",
    "        print(f\"{var_name if var_name else '<unknown>'}:\")\n",
    "        print(arg.v)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "077f9b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:\n",
      "tensor[4, 3] n=12 x∈[-1.123, 2.208] μ=0.272 σ=0.806\n",
      "tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380,  0.4617],\n",
      "        [ 0.2674,  0.5349,  0.8094]])\n",
      "\n",
      "\n",
      "targs:\n",
      "tensor[4] i64 x∈[0, 2] μ=1.250 σ=0.957 [2, 1, 2, 0]\n",
      "tensor([2, 1, 2, 0])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "logits = torch.randn(4, 3)\n",
    "targs = torch.randint(0, 3, (4,))\n",
    "\n",
    "printt(logits, targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767fd0d7",
   "metadata": {},
   "source": [
    "## Exercise 20: Problem (learning_rate_tuning): Tuning the learning rate (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1ae945e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable, Iterable\n",
    "from typing import Optional\n",
    "import torch\n",
    "import math\n",
    "class SGD(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        if lr < 0:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        defaults = {\"lr\": lr}\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure: Optional[Callable] = None):\n",
    "        loss = None if closure is None else closure()\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"] # Get the learning rate.\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "            state = self.state[p] # Get state associated with p.\n",
    "            t = state.get(\"t\", 0) # Get iteration number from the state, or initial value.\n",
    "            grad = p.grad.data # Get the gradient of loss with respect to p.\n",
    "            p.data -= lr / math.sqrt(t + 1) * grad # Update weight tensor in-place.\n",
    "            state[\"t\"] = t + 1 # Increment iteration number.\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "870e4efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.054824829101562\n",
      "13.475088119506836\n",
      "9.933258056640625\n",
      "7.771714687347412\n",
      "6.295088291168213\n",
      "5.219349384307861\n",
      "4.401828765869141\n",
      "3.761488676071167\n",
      "3.2483410835266113\n",
      "2.8296661376953125\n"
     ]
    }
   ],
   "source": [
    "def train_loop(iter, lr):\n",
    "    opt = SGD([weights], lr=lr)\n",
    "    for t in range(iter):\n",
    "        opt.zero_grad() # Reset the gradients for all learnable parameters.\n",
    "        loss = (weights**2).mean() # Compute a scalar loss value.\n",
    "        print(loss.cpu().item())\n",
    "        loss.backward() # Run backward pass, which computes gradients.\n",
    "        opt.step() # Run optimizer step.\n",
    "\n",
    "weights = torch.nn.Parameter(5 * torch.randn((10, 10)))\n",
    "train_loop(iter=10, lr=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5125334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.4075927734375\n",
      "22.4075927734375\n",
      "3.8445346355438232\n",
      "0.09200835973024368\n",
      "1.1358969903031284e-16\n",
      "1.2660276380629294e-18\n",
      "4.2631605994798736e-20\n",
      "2.5395941242960718e-21\n",
      "2.1786278328608633e-22\n",
      "2.4206976271281106e-23\n"
     ]
    }
   ],
   "source": [
    "weights = torch.nn.Parameter(5 * torch.randn((10, 10)))\n",
    "train_loop(iter=10, lr=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4d383072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.084726333618164\n",
      "26.084726333618164\n",
      "4.475431442260742\n",
      "0.10710714012384415\n",
      "8.865307553292584e-17\n",
      "9.880936080766167e-19\n",
      "3.3272584045166876e-20\n",
      "1.98207075636428e-21\n",
      "1.7003485342190746e-22\n",
      "1.8892761140718205e-23\n"
     ]
    }
   ],
   "source": [
    "weights = torch.nn.Parameter(5 * torch.randn((10, 10)))\n",
    "train_loop(iter=10, lr=1e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda938a",
   "metadata": {},
   "source": [
    "As lr goes up, the loss falls faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37487fb",
   "metadata": {},
   "source": [
    "## Exercise 21: Problem (adamw): Implement AdamW (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62667be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2a7b5be",
   "metadata": {},
   "source": [
    "## Exercise 22: Problem (adamwAccounting): Resource accounting for training with AdamW (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9152af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12650d6b",
   "metadata": {},
   "source": [
    "## Exercise 23: Problem (learning_rate_schedule): Implement cosine learning rate schedule with warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c974bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(t, alpha_max, alpha_min, tw, tc):\n",
    "    # t - time step\n",
    "    # alpha_max - max learning rate\n",
    "    # alpha min - min learning rate\n",
    "    # tw - warmup iterations\n",
    "    # tc - number of cosine annealing iterations\n",
    "    if t < tw:\n",
    "        lr = (t / tw) * alpha_max\n",
    "    else:\n",
    "        lr = alpha_max\n",
    "    return lr\n",
    "\n",
    "time_steps = 1000\n",
    "lrs = [lr_scheduler(t, 0.1, 0.0001, 50, 750) for t in range(0, time_steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eda5f7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(time_steps), lrs)\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Warm-up Learning Rate Scheduler (not optimal)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895195e5",
   "metadata": {},
   "source": [
    "Now, let's add the cosine annealing to the simple warmup scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5ef55651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(t, alpha_max, alpha_min, tw, tc):\n",
    "    # t - time step\n",
    "    # alpha_max - max learning rate\n",
    "    # alpha min - min learning rate\n",
    "    # tw - warmup iterations\n",
    "    # tc - number of cosine annealing iterations\n",
    "    if t < tw:\n",
    "        lr = (t / tw) * alpha_max\n",
    "    elif tw <= t < tc:\n",
    "        lr = alpha_min + 0.5 * (1 + math.cos(math.pi * (t - tw) / (tc - tw))) * (alpha_max - alpha_min)\n",
    "    else:\n",
    "        lr = alpha_min\n",
    "    return lr\n",
    "\n",
    "time_steps = 1000\n",
    "lrs = [lr_scheduler(t, 0.1, 0.0001, 50, 750) for t in range(0, time_steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "29c37be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(time_steps), lrs)\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Cosine-annealing Learning Rate Scheduler')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bda27",
   "metadata": {},
   "source": [
    "## Exercise 24: Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "63e351f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_clipping(grads, M, eps=1e-6):\n",
    "    # g - gradient parameters\n",
    "    # M - max norm\n",
    "    for g in grads:\n",
    "        norm = torch.norm(g)\n",
    "        if norm < M:\n",
    "            continue\n",
    "        else:\n",
    "            g.mul_(M / (norm + eps))\n",
    "    return grads\n",
    "\n",
    "torch.manual_seed(42)\n",
    "tensors = [torch.nn.Parameter(torch.randn(4, 5), requires_grad=True) for _ in range(5)]\n",
    "\n",
    "# gradient_clipping(g, 0.01) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13bc43",
   "metadata": {},
   "source": [
    "## Exercise 25: Problem (data_loading): Implement data loading (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b87d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
