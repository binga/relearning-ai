{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7bca9b",
   "metadata": {},
   "source": [
    "# CS336 Assignments\n",
    "\n",
    "| # | Topic                         | Description                                 |\n",
    "|---|-------------------------------|---------------------------------------------|\n",
    "| 1 | Basics                        | Train an LLM from scratch                   |\n",
    "| 2 | Systems                       | Make it run fast!                           |\n",
    "| 3 | Scaling                       | Make it performant at a FLOP budget         |\n",
    "| 4 | Data                          | Prepare the right datasets                  |\n",
    "| 5 | Alignment & Reasoning RL      | Align it to real-world use cases            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f19a5c",
   "metadata": {},
   "source": [
    "### Assignment #1\n",
    "- Implement all of the components (tokenizer, model, loss function, optimizer) necessary to train a standard Transformer language model\n",
    "- Train a minimal language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fad44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from datasets import load_dataset\n",
    "import joblib\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29cb95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 97,\n",
       " 'b': 98,\n",
       " 'c': 99,\n",
       " 'd': 100,\n",
       " 'e': 101,\n",
       " 'f': 102,\n",
       " 'g': 103,\n",
       " 'h': 104,\n",
       " 'i': 105,\n",
       " 'j': 106,\n",
       " 'k': 107,\n",
       " 'l': 108,\n",
       " 'm': 109,\n",
       " 'n': 110,\n",
       " 'o': 111,\n",
       " 'p': 112,\n",
       " 'q': 113,\n",
       " 'r': 114,\n",
       " 's': 115,\n",
       " 't': 116,\n",
       " 'u': 117,\n",
       " 'v': 118,\n",
       " 'w': 119,\n",
       " 'x': 120,\n",
       " 'y': 121,\n",
       " 'z': 122,\n",
       " 'A': 65,\n",
       " 'B': 66,\n",
       " 'C': 67,\n",
       " 'D': 68,\n",
       " 'E': 69,\n",
       " 'F': 70,\n",
       " 'G': 71,\n",
       " 'H': 72,\n",
       " 'I': 73,\n",
       " 'J': 74,\n",
       " 'K': 75,\n",
       " 'L': 76,\n",
       " 'M': 77,\n",
       " 'N': 78,\n",
       " 'O': 79,\n",
       " 'P': 80,\n",
       " 'Q': 81,\n",
       " 'R': 82,\n",
       " 'S': 83,\n",
       " 'T': 84,\n",
       " 'U': 85,\n",
       " 'V': 86,\n",
       " 'W': 87,\n",
       " 'X': 88,\n",
       " 'Y': 89,\n",
       " 'Z': 90}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_letters\n",
    "\n",
    "{l: ord(l) for l in ascii_letters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82da92ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(115)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd26ea",
   "metadata": {},
   "source": [
    "### Exercise 1: Problem (unicode1): Understanding Unicode (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92f1886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81842e52",
   "metadata": {},
   "source": [
    "This represents a null character often used to represent end of a string. It is also called an escape sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd338fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\x00'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr('\\x00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cc439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "382b1b51",
   "metadata": {},
   "source": [
    "The string representation of this character is '\\x00'. When this string is passed to print function, it's rendered as null as that is the purpose of this character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb1d013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c1bdc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edeebc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12691eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5f80c",
   "metadata": {},
   "source": [
    "When we print the character with the print function, the character is executed and hence renders nothing on the stdout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32a387",
   "metadata": {},
   "source": [
    "### Exercise 2: Problem (unicode2): Unicode Encodings (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fddecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_string_encoded: b'Hello'\n",
      "Byte values: [72, 101, 108, 108, 111]\n",
      "test string decoded: Hello\n"
     ]
    }
   ],
   "source": [
    "test_string = \"Hello\"\n",
    "test_string_encoded = test_string.encode(\"UTF-8\")\n",
    "print(f\"test_string_encoded: {test_string_encoded}\")\n",
    "print(f\"Byte values: {list(test_string_encoded)}\")\n",
    "print(f\"test string decoded: {test_string_encoded.decode(\"UTF-8\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bca8fe",
   "metadata": {},
   "source": [
    "(a) What are some reasons to prefer training our tokenizer on UTF-8 encoded bytes, rather than\n",
    "UTF-16 or UTF-32? It may be helpful to compare the output of these encodings for various\n",
    "input strings\n",
    "\n",
    "A: Majority of the internet comprises of UTF-8 characters. And, UTF-8 is space efficient as 5 characters in UTF-8 takes 5 bytes whereas UTF-16 and UTF-32 takes 2x and 4x the bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b7879d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcafÃ©\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "decode_utf8_bytes_to_str_wrong(\"cafÃ©\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f465a",
   "metadata": {},
   "source": [
    "The function attempts to convert each character as a standalone single character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc26adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cafÃ©\".encode(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93e0a7",
   "metadata": {},
   "source": [
    "## Exercise 3: Problem (train_bpe): BPE Tokenizer Training (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eaf49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(input_path, vocab_size=1000, special_tokens=[]):\n",
    "    vocab, merges = None, None\n",
    "\n",
    "    return vocab, merges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaef1b9",
   "metadata": {},
   "source": [
    "## Exercise 4: Problem (train_bpe_tinystories): BPE Training on TinyStories (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9f3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe_tinystories(input_path, vocab_size=10000, special_tokens=[\"|endoftext|\"]):\n",
    "    vocab, merges = None, None\n",
    "\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e844a74",
   "metadata": {},
   "source": [
    "## Exercise 5: Problem (train_bpe_expts_owt): BPE Training on OpenWebText (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "647fe501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe_expts_owt(input_path, vocab_size=32000, special_tokens=[\"|endoftext|\"]):\n",
    "    vocab, merges = None, None\n",
    "\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01767cd1",
   "metadata": {},
   "source": [
    "## Exercise 6: Problem (tokenizer): Implementing the tokenizer (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd29c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPETokkenizer():\n",
    "    def __init__(self, vocab, merges, special_tokens=None):\n",
    "        pass\n",
    "\n",
    "    def encode(self, text:str):\n",
    "        pass\n",
    "\n",
    "    def decode(self, ids:list[str]):\n",
    "        pass\n",
    "\n",
    "    def from_files():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3652ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2771b5a7",
   "metadata": {},
   "source": [
    "## Exercise 7: Problem (tokenizer_experiments): Experiments with tokenizers (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68591549",
   "metadata": {},
   "source": [
    "a. Sample 10 documents from TinyStories and OpenWebText. Using your previously-trained TinyStories and OpenWebText tokenizers (10K and 32K vocabulary size, respectively), encode these sampled documents into integer IDs. What is each tokenizerâs compression ratio (bytes/token)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1a20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867e2c53",
   "metadata": {},
   "source": [
    "b. What happens if you tokenize your OpenWebText sample with the TinyStories tokenizer? Com\u0002pare the compression ratio and/or qualitatively describe what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d881be8b",
   "metadata": {},
   "source": [
    "## Exercise 8: Problem (linear): Implementing the linear module (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c7714b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[3, 2] n=6 xâ[-1.725, 0.063] Î¼=-0.740 Ï=0.702 grad ViewBackward0 [[-1.281, -1.725], [-0.531, -0.048], [0.063, -0.920]]\n",
       "tensor([[-1.2815, -1.7247],\n",
       "        [-0.5314, -0.0480],\n",
       "        [ 0.0631, -0.9196]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MyLinear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        weight = torch.empty(in_features, out_features)\n",
    "        sigma = sqrt(2 / (in_features + out_features))\n",
    "        torch.nn.init.trunc_normal_(weight, mean=0, std=sigma, a=-3 * sigma, b=3 * sigma)\n",
    "\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        # output = x @ self.W \n",
    "\n",
    "        # einsum way\n",
    "        output = einsum(x, self.W, \"... j, j k-> ... k\")\n",
    "\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MyLinear(5, 2)\n",
    "\n",
    "batch = torch.randn(3, 5)\n",
    "\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103cee67",
   "metadata": {},
   "source": [
    "## Exercise 9: Problem (embedding): Implement the embedding module (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146775a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[4] i64 xâ[0, 9] Î¼=4.500 Ï=5.196 [0, 9, 0, 9]\n",
      "tensor([0, 9, 0, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor[4, 5] n=20 xâ[-0.856, 1.729] Î¼=0.398 Ï=0.862 grad IndexBackward0\n",
       "tensor([[ 1.1812,  1.3651, -0.2971,  1.7287, -0.2774],\n",
       "        [-0.5769,  0.7990,  0.2255,  0.6847, -0.8557],\n",
       "        [ 1.1812,  1.3651, -0.2971,  1.7287, -0.2774],\n",
       "        [-0.5769,  0.7990,  0.2255,  0.6847, -0.8557]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MyEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        weight = torch.empty(num_embeddings, embedding_dim)\n",
    "        torch.nn.init.trunc_normal_(weight, mean=0, std=1, a=-3, b=3)\n",
    "\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        output = self.W[x]\n",
    "\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MyEmbedding(10, 5)\n",
    "\n",
    "batch = torch.randint(0, 10, (4, ))\n",
    "\n",
    "print(batch.v)\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f610c2d",
   "metadata": {},
   "source": [
    "## Exercise 10: Problem (rmsnorm): Root Mean Square Layer Normalization (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b8ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 8] n=32 xâ[-1.502, 1.712] Î¼=0.232 Ï=0.988 grad MulBackward0\n",
       "tensor([[ 1.3741,  1.0606,  0.6423, -1.5015,  0.4838, -0.8804, -0.0307, -1.1443],\n",
       "        [-0.7808,  1.7116, -0.4074, -1.4571, -0.7556, -0.5807, -0.7981,  0.7915],\n",
       "        [ 1.6059, -0.1561, -0.4864,  0.4298, -0.7413,  1.0544,  0.7831,  1.6434],\n",
       "        [ 1.4381,  1.4575,  0.6863,  1.5006, -0.2604,  0.0469, -0.2828,  0.9667]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MyRMSNorm(torch.nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-5, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        weight = torch.ones(d_model)\n",
    "        self.W = torch.nn.Parameter(weight)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        output = x.to(torch.float32)\n",
    "        denom = torch.sqrt(output.pow(2).mean(dim=-1, keepdim=True) + self.eps)\n",
    "        output = output / denom\n",
    "        output = output * self.W\n",
    "        output = output.to(self.dtype)\n",
    "        return output\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyRMSNorm(8)\n",
    "\n",
    "batch = torch.randn((4, 8))\n",
    "\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00f6fd",
   "metadata": {},
   "source": [
    "## Exercise 11: Problem (positionwise_feedforward): Implement the position-wise feed-forward network (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b37cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 8] n=32 xâ[-0.278, 1.682] Î¼=0.360 Ï=0.627\n",
       "tensor([[ 1.6820,  1.2131,  0.6405, -0.2286,  0.4501, -0.2783, -0.0211, -0.2685],\n",
       "        [-0.2410,  1.3828, -0.1582, -0.2769, -0.2370, -0.2035, -0.2435,  0.5199],\n",
       "        [ 1.3760, -0.0734, -0.1881,  0.2673, -0.2419,  0.8046,  0.5527,  1.4167],\n",
       "        [ 1.0007,  1.0180,  0.3956,  1.0566, -0.1025,  0.0213, -0.1100,  0.6042]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from einops import einsum\n",
    "\n",
    "class MySilu(torch.nn.Module):\n",
    "    def __init__(self, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        sigm = torch.sigmoid(x)\n",
    "        output = x * sigm\n",
    "        return output\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MySilu()\n",
    "\n",
    "batch = torch.randn((4, 8))\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de58d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 6] n=24 xâ[-74.395, 109.831] Î¼=3.797 Ï=42.568\n",
       "tensor([[-42.3801,  40.7463, -21.8935, -74.3954, -37.8143,  -8.6413],\n",
       "        [-27.2500,  88.8632,  -8.8330, 109.8314, -22.7258,  37.7100],\n",
       "        [ 49.0109,  16.9329, -37.6880,  20.9207,  39.5458, -37.6875],\n",
       "        [  1.6938,  -1.8043,  -1.4190,  13.6263,  14.5836, -19.7981]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt, ceil\n",
    "from einops import einsum, rearrange\n",
    "\n",
    "# https://arxiv.org/pdf/2002.05202\n",
    "class MySwiGlu(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_ff, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = int(ceil(8*d_model // 3 / 64) * 64)\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.silu = MySilu()\n",
    "        self.w1 = torch.randn((self.d_ff, self.d_model))\n",
    "        self.w2 = torch.randn((self.d_model, self.d_ff))\n",
    "        self.w3 = torch.randn((self.d_ff, self.d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # PyTorch way\n",
    "        # o1 = self.silu(x @ self.w1.T)\n",
    "        # o3 = x @ self.w3.T\n",
    "        # gated = o1 * o3\n",
    "        # o = gated @ self.w2.T\n",
    "\n",
    "        # einsum way\n",
    "        o1 = einsum(x, self.w1, \"... d_model, d_ff d_model -> ... d_ff\")\n",
    "        o3 = einsum(x, self.w3, \"... d_model, d_ff d_model -> ... d_ff\")\n",
    "        gated = self.silu(o1) * o3\n",
    "        o = einsum(gated, self.w2, \"... d_ff, d_model d_ff -> ... d_model\")\n",
    "        return o\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = MySwiGlu(6, 16)\n",
    "\n",
    "batch = torch.randn((4, 6))\n",
    "output = model(batch)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d0273",
   "metadata": {},
   "source": [
    "## Exercise 12: Problem (rope): Implement RoPE (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914e930",
   "metadata": {},
   "source": [
    "Rotation matrix derivation: https://www.youtube.com/watch?v=EZufiIwwqFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63e3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 4, 8] n=64 xâ[-2.106, 2.110] Î¼=-0.066 Ï=1.056\n",
       "tensor([[[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431,\n",
       "          -1.6047],\n",
       "         [-1.7937,  0.2579, -0.2504, -1.4358, -0.7223, -0.5667, -0.7696,\n",
       "           0.7617],\n",
       "         [-0.5383,  1.5598, -0.5748,  0.3320, -0.7795,  1.0629,  0.7974,\n",
       "           1.6822],\n",
       "         [-1.4493, -1.1029,  0.1888,  1.4555, -0.2328,  0.0348, -0.2542,\n",
       "           0.8591]],\n",
       "\n",
       "        [[-1.3847, -0.8712, -0.2234,  1.7174,  0.3189, -0.4245,  0.3057,\n",
       "          -0.7746],\n",
       "         [-1.6794, -0.7727, -0.8154, -0.6860, -1.2953,  2.1099, -1.2342,\n",
       "          -0.4891],\n",
       "         [ 0.9787, -0.5571, -0.0280,  0.5308, -0.5117,  1.1814, -0.8125,\n",
       "          -0.7376],\n",
       "         [ 1.3841, -0.2337, -0.2603,  0.6267, -0.1531,  1.8408, -1.1887,\n",
       "           1.3800]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relearn this!\n",
    "class MyRoPE(torch.nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta = theta\n",
    "        self.d_k = d_k\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.device = device\n",
    "        self.rotation_matrix_table = self.generate_rotation_matrix(theta, d_k, max_seq_len)\n",
    "        self.register_buffer('rotation_matrix', self.rotation_matrix_table, persistent=False)\n",
    "\n",
    "    def generate_rotation_block(self, theta, block_index, seq_pos, d_k):\n",
    "        angle = torch.tensor(seq_pos / (theta ** (2 * block_index / d_k)))\n",
    "        cos = torch.cos(angle)\n",
    "        sin = torch.sin(angle)\n",
    "        rotation_matrix = torch.Tensor([[cos, -sin], [sin, cos]])\n",
    "        return rotation_matrix\n",
    "    \n",
    "    def generate_rotation_matrix(self, theta, d_k, max_seq_len):\n",
    "        rotation_matrix_table = torch.zeros(max_seq_len, d_k, d_k)\n",
    "        for i in range(max_seq_len):\n",
    "            blocks = [self.generate_rotation_block(theta, k, i, d_k) for k in range(d_k // 2)]\n",
    "            rotation_matrix_table[i, :, :] = torch.block_diag(*blocks)\n",
    "        return rotation_matrix_table\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor = None):\n",
    "        *dims, seq_len, d_k = x.shape\n",
    "        if token_positions is None:\n",
    "            token_positions = torch.arange(seq_len, device=x.device)\n",
    "        rotation_matrix = self.rotation_matrix_table[token_positions]\n",
    "        x_rotated = rotation_matrix @ x.unsqueeze(-1)\n",
    "        x_rotated = x_rotated.squeeze(-1)\n",
    "        return x_rotated\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "batch = torch.randn((2, 4, 8))\n",
    "model = MyRoPE(10000, 8, 12)\n",
    "tok_positions = torch.arange(4)\n",
    "output = model(batch, tok_positions)\n",
    "output.v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6a2fc",
   "metadata": {},
   "source": [
    "## Exercise 13: Problem (softmax): Implement softmax (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12f5579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4, 8] n=32 xâ[0.007, 0.507] Î¼=0.125 Ï=0.119\n",
       "tensor([[0.3971, 0.2558, 0.1423, 0.0070, 0.1139, 0.0168, 0.0554, 0.0116],\n",
       "        [0.0460, 0.5071, 0.0659, 0.0240, 0.0471, 0.0557, 0.0452, 0.2090],\n",
       "        [0.2693, 0.0444, 0.0317, 0.0809, 0.0244, 0.1532, 0.1161, 0.2799],\n",
       "        [0.2011, 0.2046, 0.1031, 0.2126, 0.0444, 0.0584, 0.0435, 0.1323]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MySoftmax(x: torch.Tensor, dim: int):\n",
    "    eps = 1e-8\n",
    "    \n",
    "    # numerical stability at high values of logits\n",
    "    # dim-wise max and not overall max\n",
    "    max = torch.max(x, dim=dim, keepdim=True)[0]\n",
    "    x = x - max\n",
    "\n",
    "    # usual business here\n",
    "    num = torch.exp(x)\n",
    "    denom = torch.exp(x).sum(dim=dim, keepdim=True)\n",
    "    output = num / (denom + eps)\n",
    "    return output\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch = torch.randn((4, 8))\n",
    "output = MySoftmax(batch, -1)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaeb2dd",
   "metadata": {},
   "source": [
    "## Exercise 14: Problem (scaled_dot_product_attention): Implement scaled dot-product attention (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a01b1827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 4, 8] n=64 xâ[-1.408, 2.151] Î¼=0.076 Ï=0.790\n",
       "tensor([[[-0.1561, -0.6953,  0.7203, -0.3861, -0.2114,  2.0479,  2.1509,\n",
       "           1.6704],\n",
       "         [-0.4206, -0.5915,  0.7682, -0.6597, -0.2825,  1.3089,  1.5757,\n",
       "           0.8848],\n",
       "         [-1.4079, -0.8897,  0.9736, -0.5634,  0.2719, -0.5261, -0.4475,\n",
       "           0.4843],\n",
       "         [-0.4120, -0.4365,  0.9151,  0.0516, -0.2064,  0.1070,  0.1036,\n",
       "           0.5917]],\n",
       "\n",
       "        [[ 1.9627, -0.3493, -0.4200, -0.1452, -0.2851, -1.0392,  0.1441,\n",
       "           0.8603],\n",
       "         [ 0.7856, -0.7519,  0.2780, -0.0635, -1.0282, -0.3954,  0.2636,\n",
       "           0.0057],\n",
       "         [-0.1239, -0.6923,  0.7523,  0.5994,  0.5321,  0.0085,  0.7380,\n",
       "          -1.0673],\n",
       "         [ 0.1558, -0.8902,  0.0420, -0.2327, -0.4623, -0.6036,  0.4148,\n",
       "          -0.4519]]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def Myscaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    #  ## einsum approach\n",
    "    attn_scores = einsum(Q, K, \"... queries d_k, ... keys d_k -> ... queries keys\")\n",
    "    attn_weights = attn_scores / torch.sqrt(torch.tensor(Q.shape[-1]))\n",
    "\n",
    "    if mask is not None:\n",
    "        attn_weights = attn_weights.masked_fill(mask == 0, -torch.inf)\n",
    "\n",
    "    attn_weights = MySoftmax(attn_weights, dim=-1)\n",
    "    context_vec = einsum(attn_weights, V, \"... queries sl, ... sl d_v -> ... queries d_v\")\n",
    "    return context_vec\n",
    "    \n",
    "torch.manual_seed(420)\n",
    "\n",
    "Q = torch.randn((2, 4, 8))\n",
    "K = torch.randn((2, 4, 8))\n",
    "V = torch.randn((2, 4, 8))\n",
    "\n",
    "# creating a mask\n",
    "mask = torch.randn((2, 4, 4))\n",
    "mask = torch.triu(mask, diagonal=1).to(bool)\n",
    "\n",
    "output = Myscaled_dot_product_attention(Q, K, V, ~mask)\n",
    "output.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30452c",
   "metadata": {},
   "source": [
    "## Exercise 15: Problem (multihead_self_attention): Implement causal multi-head self-attention (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2441a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 8] n=96 xâ[-37.604, 44.982] Î¼=1.520 Ï=13.757 grad ViewBackward0\n",
       "tensor([[[ 44.9816,  -4.0572,   9.5668,  17.2590, -17.3515, -10.4152,  -7.6936,\n",
       "          -34.4534],\n",
       "         [ 14.4895,   2.1835,  26.0109,  20.7137, -21.6453,   4.8867,  -5.4112,\n",
       "           -2.5018],\n",
       "         [ -1.0056,  -4.4707, -16.1527,   2.4396,  11.6497,   0.6426,  11.3221,\n",
       "           -0.1446],\n",
       "         [  5.1057,  -6.8183, -17.2269,   4.7302,  14.0615,   1.3946,  11.8164,\n",
       "           -8.1424],\n",
       "         [-11.7404,  -3.6162, -10.8130, -17.4299,  11.6551,  -4.4994,  -0.2479,\n",
       "            3.2620],\n",
       "         [-24.8512,   7.8084,  22.2743,   3.1124, -10.6928,  30.2615,   5.8352,\n",
       "           30.7121]],\n",
       "\n",
       "        [[-19.2817,  -1.2965,   6.4948,  -8.5323,   2.0376,   7.6350,   2.2789,\n",
       "           13.9557],\n",
       "         [-37.6042,   6.6201,  10.2247,  -0.6709,   3.2950,  16.9392,   5.3303,\n",
       "           33.0000],\n",
       "         [ -2.9748,  -4.8768,   5.5871,  16.4281,   4.5379, -12.4719,  -1.8378,\n",
       "           -4.0125],\n",
       "         [-21.2404,   0.7599,  29.9460,   9.5963,  -9.8929,   5.2589,  -4.9882,\n",
       "           17.6042],\n",
       "         [ -1.5435,   5.8131,  -6.8222,  -5.0511,   1.0927,   4.3094,   2.0665,\n",
       "            2.2948],\n",
       "         [ -2.6097,   3.5150, -20.3922,  -6.9153,  11.8712,   4.8558,   6.2314,\n",
       "            2.5145]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "from torch.nn import Linear\n",
    "\n",
    "class MyCausalMHA(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, max_seq_len=None, theta=10000, device=None, use_rope=False, token_positions=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_k = int(d_model / num_heads)\n",
    "        self.use_rope = use_rope\n",
    "        self.rope = MyRoPE(theta, self.d_k, max_seq_len) if use_rope else None\n",
    "        self.token_positions = token_positions\n",
    "\n",
    "        self.q_proj = Linear(d_model, d_model)\n",
    "        self.k_proj = Linear(d_model, d_model)\n",
    "        self.v_proj = Linear(d_model, d_model)\n",
    "        self.o_proj = Linear(d_model, d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, sl, d_model = x.shape\n",
    "\n",
    "        # queries = einsum(x, self.q_proj.weight, \"... sl d_m, d_m d_m -> ... sl d_m\")\n",
    "        # keys = einsum(x, self.k_proj.weight, \"... sl d_m, d_m d_m -> ... sl d_m\")\n",
    "        # values = einsum(x, self.v_proj.weight, \"... sl d_m, d_m d_m -> ... sl d_m\")\n",
    "\n",
    "        queries = self.q_proj(x)\n",
    "        keys = self.k_proj(x)\n",
    "        values = self.v_proj(x)\n",
    "\n",
    "        # Expand the head dimension into it's own dimension and transpose for self-attention soon\n",
    "        queries = rearrange(queries, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        keys = rearrange(keys, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        values = rearrange(values, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "\n",
    "        # use rope if needed\n",
    "        if self.use_rope:\n",
    "            queries = self.rope(queries, self.token_positions)\n",
    "            keys = self.rope(keys, self.token_positions)\n",
    "\n",
    "        # apply causal mask``\n",
    "        causal_mask = torch.ones((sl, sl))\n",
    "        causal_mask = torch.triu(causal_mask, diagonal=1).to(bool)\n",
    "        context_vec = Myscaled_dot_product_attention(queries, keys, values, ~causal_mask)\n",
    "\n",
    "        # concatenate head with o_projection & pass it through o_proj\n",
    "        context_vec = rearrange(context_vec, \"... h sl d_v -> ... sl (h d_v)\")\n",
    "        # output = einsum(context_vec, self.o_proj, \"... sl d_model, d_model d_v -> ... sl d_v\")\n",
    "        output = self.o_proj(context_vec)\n",
    "        return output\n",
    "\n",
    "    \n",
    "\n",
    "torch.manual_seed(42)\n",
    "m = torch.randn(8, 8)\n",
    "model = MyCausalMHA(d_model=8, num_heads=2, max_seq_len=10, use_rope=False)\n",
    "model.q_proj.weight.data.copy_(m)\n",
    "model.k_proj.weight.data.copy_(m)\n",
    "model.v_proj.weight.data.copy_(m)\n",
    "model.o_proj.weight.data.copy_(m)\n",
    "\n",
    "model.q_proj.bias.data.zero_()\n",
    "model.k_proj.bias.data.zero_()\n",
    "model.v_proj.bias.data.zero_()\n",
    "model.o_proj.bias.data.zero_()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "batch = torch.randn((2, 6, 8))\n",
    "context_vec1 = model(batch)\n",
    "context_vec1.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e858ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dc26356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 8] n=96 xâ[-37.604, 44.982] Î¼=1.520 Ï=13.757\n",
       "tensor([[[ 44.9816,  -4.0572,   9.5668,  17.2590, -17.3515, -10.4152,  -7.6936,\n",
       "          -34.4534],\n",
       "         [ 14.4895,   2.1835,  26.0109,  20.7137, -21.6453,   4.8867,  -5.4112,\n",
       "           -2.5018],\n",
       "         [ -1.0056,  -4.4707, -16.1527,   2.4396,  11.6497,   0.6426,  11.3221,\n",
       "           -0.1446],\n",
       "         [  5.1057,  -6.8183, -17.2269,   4.7302,  14.0615,   1.3946,  11.8164,\n",
       "           -8.1424],\n",
       "         [-11.7404,  -3.6162, -10.8130, -17.4299,  11.6551,  -4.4994,  -0.2479,\n",
       "            3.2620],\n",
       "         [-24.8512,   7.8084,  22.2743,   3.1124, -10.6928,  30.2615,   5.8352,\n",
       "           30.7121]],\n",
       "\n",
       "        [[-19.2817,  -1.2965,   6.4948,  -8.5323,   2.0376,   7.6350,   2.2789,\n",
       "           13.9557],\n",
       "         [-37.6042,   6.6201,  10.2247,  -0.6709,   3.2950,  16.9392,   5.3303,\n",
       "           33.0000],\n",
       "         [ -2.9748,  -4.8768,   5.5871,  16.4281,   4.5379, -12.4719,  -1.8378,\n",
       "           -4.0125],\n",
       "         [-21.2404,   0.7599,  29.9460,   9.5963,  -9.8929,   5.2589,  -4.9882,\n",
       "           17.6042],\n",
       "         [ -1.5435,   5.8131,  -6.8222,  -5.0511,   1.0927,   4.3094,   2.0665,\n",
       "            2.2948],\n",
       "         [ -2.6097,   3.5150, -20.3922,  -6.9153,  11.8712,   4.8558,   6.2314,\n",
       "            2.5145]]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCausalMHA2(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, max_seq_len=None, theta=10000, device=None, use_rope=False, token_positions=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_k = int(d_model / num_heads)\n",
    "        self.use_rope = use_rope\n",
    "        self.rope = MyRoPE(theta, self.d_k, max_seq_len) if use_rope else None\n",
    "        self.token_positions = token_positions\n",
    "\n",
    "        self.q_proj = torch.randn(d_model, d_model)\n",
    "        self.k_proj = torch.randn(d_model, d_model)\n",
    "        self.v_proj = torch.randn(d_model, d_model)\n",
    "        self.o_proj = torch.randn(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, sl, d_model = x.shape\n",
    "\n",
    "        # einsum notation\n",
    "        queries = einsum(x, self.q_proj, \"... sl d_m, d_k d_m -> ... sl d_k\")\n",
    "        keys = einsum(x, self.k_proj, \"... sl d_m, d_k d_m -> ... sl d_k\")\n",
    "        values = einsum(x, self.v_proj, \"... sl d_m, d_k d_m -> ... sl d_k\")\n",
    "\n",
    "        # pytorch matrix notation\n",
    "        # CAREFUL: be very careful with transposing as PyTorch stores linear layers in (out_features, in_features) form\n",
    "        # queries = x @ self.q_proj.T\n",
    "        # keys = x @ self.k_proj.T\n",
    "        # values = x @ self.v_proj.T\n",
    "\n",
    "        # Expand the head dimension into it's own dimension and transpose for self-attention soon\n",
    "        queries = rearrange(queries, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        keys = rearrange(keys, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "        values = rearrange(values, \"... sl (h d_head) -> ... h sl d_head\", h=self.num_heads)\n",
    "\n",
    "        # use rope if needed\n",
    "        if self.use_rope:\n",
    "            queries = self.rope(queries, self.token_positions)\n",
    "            keys = self.rope(keys, self.token_positions)\n",
    "\n",
    "        # apply causal mask\n",
    "        causal_mask = torch.ones((sl, sl))\n",
    "        causal_mask = torch.triu(causal_mask, diagonal=1).to(bool)\n",
    "        context_vec = Myscaled_dot_product_attention(queries, keys, values, ~causal_mask) # CAREFUL: causal_mask should not attend to future tokens\n",
    "\n",
    "        # concatenate head with o_projection & pass it through o_proj\n",
    "        context_vec = rearrange(context_vec, \"... h sl d_v -> ... sl (h d_v)\")\n",
    "        output = einsum(context_vec, self.o_proj, \"... sl d_model, d_v d_model -> ... sl d_v\")\n",
    "        # output = context_vec @ self.o_proj.T\n",
    "        return output\n",
    "    \n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyCausalMHA2(d_model=8, num_heads=2, max_seq_len=10, use_rope=False)\n",
    "model.q_proj.data.copy_(m)\n",
    "model.k_proj.data.copy_(m)\n",
    "model.v_proj.data.copy_(m)\n",
    "model.o_proj.data.copy_(m)\n",
    "\n",
    "context_vec2 = model(batch)\n",
    "context_vec2.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1e21d85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(context_vec1, context_vec2, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a05c75",
   "metadata": {},
   "source": [
    "## Exercise 16: Problem (transformer_block): Implement the Transformer block (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "4d894ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 8] n=96 xâ[-131.735, 125.800] Î¼=-0.974 Ï=53.200 grad AddBackward0\n",
       "tensor([[[ -30.6578,   33.7612,   35.9949,  -13.0006, -113.8567,   44.8295,\n",
       "            94.9931,  -44.8292],\n",
       "         [ -34.0975,   51.0059,   41.1780,  -19.0532,  -78.3312,   31.9316,\n",
       "            57.9824,  -17.0674],\n",
       "         [ -72.8474, -131.7351,  -25.1189,  -12.0696,   11.0075,   16.2014,\n",
       "            44.7393,  -32.0036],\n",
       "         [ -38.0562,  -36.5616,   36.2781,    8.6351,  -61.7301,   39.3872,\n",
       "            76.6221,  -36.4891],\n",
       "         [ -18.7337,  -31.8101,   13.3985,  -25.0176,  -11.5342,   33.5430,\n",
       "            60.6820,  -36.9917],\n",
       "         [  29.1150,   28.7488,  -55.5202,  -41.5676,   31.3636,   41.8333,\n",
       "            34.3643,  -23.0237]],\n",
       "\n",
       "        [[  -5.0573,  125.7999,   20.2271,  -59.8220, -107.2766,   68.2812,\n",
       "            47.9998,  -14.3731],\n",
       "         [ -61.9032,  -57.3246,  -19.4308,    5.0884,   -2.7076,   21.9048,\n",
       "             2.9424,   33.5769],\n",
       "         [ -24.3774,  -10.0657,   42.8495,   60.4710,  -46.1791,  -40.8142,\n",
       "           -48.5564,  -13.8084],\n",
       "         [  70.8347,   27.2074,   68.1606,   94.7534,  -72.5252,  -16.0102,\n",
       "           -68.7625,   56.5744],\n",
       "         [ -25.6330,  -40.5323,   -2.3343,   44.2679,  -26.8085,   44.6750,\n",
       "            24.2750,  -19.5150],\n",
       "         [  14.8456,   50.5467,  -92.5855, -116.6030,  -13.9043,  101.9974,\n",
       "           121.9304,  -91.6963]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyTransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, d_ff: int, max_seq_len=10000, theta=10000, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.device = device\n",
    "        self.attn = MyCausalMHA2(d_model=d_model, num_heads=num_heads, max_seq_len=max_seq_len, theta=theta, use_rope=True, device=device)\n",
    "        self.ffn = MySwiGlu(d_model=d_model, d_ff=d_ff, device=device, dtype=dtype)\n",
    "        self.attnorm = MyRMSNorm(d_model=d_model, device=device, dtype=dtype)\n",
    "        self.ffnnorm = MyRMSNorm(d_model=d_model, device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        bs, sl, d_model = x.shape\n",
    "\n",
    "        x_norm = self.attnorm(x)\n",
    "        x_attn = self.attn(x_norm)\n",
    "        x_add = x + x_attn\n",
    "\n",
    "        x_ffn_norm = self.ffnnorm(x_add)\n",
    "        x_ffn = self.ffn(x_ffn_norm)\n",
    "        x_final = x_add + x_ffn\n",
    "        return x_final\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyTransformerBlock(d_model=8, num_heads=2, d_ff=64, max_seq_len=1000)\n",
    "\n",
    "batch = torch.randn((2, 6, 8))\n",
    "context_vec = model(batch)\n",
    "context_vec.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
