{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c8a830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phani/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1becc952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertModel.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782a9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd5eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3159b0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.705, 0.498] μ=6.249e-05 σ=0.043 grad,\n",
       " Parameter[768] 3Kb x∈[-1.078, 1.100] μ=0.009 σ=0.324 grad,\n",
       " Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.937, 0.782] μ=1.131e-05 σ=0.043 grad,\n",
       " Parameter[768] 3Kb x∈[-0.012, 0.011] μ=-0.000 σ=0.003 grad,\n",
       " Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.190, 0.200] μ=-7.438e-05 σ=0.034 grad,\n",
       " Parameter[768] 3Kb x∈[-0.371, 0.420] μ=0.005 σ=0.081 grad,\n",
       " Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.610, 0.740] μ=-2.041e-05 σ=0.035 grad,\n",
       " Parameter[768] 3Kb x∈[-0.556, 0.135] μ=-0.001 σ=0.047 grad]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in model.transformer.layer[0].attention.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25eb1f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l for l in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7d1e176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66362880"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[1].numel() for x in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57289dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23835648"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([l[1].numel() for l in model.named_parameters() if 'em' in l[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1e11adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('embeddings.word_embeddings.weight',\n",
       "  Parameter[30522, 768] n=23440896 (89Mb) x∈[-1.095, 0.594] μ=-0.038 σ=0.047 grad),\n",
       " ('embeddings.position_embeddings.weight',\n",
       "  Parameter[512, 768] n=393216 (1.5Mb) x∈[-0.949, 0.727] μ=-3.874e-05 σ=0.016 grad),\n",
       " ('embeddings.LayerNorm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.086, 0.932] μ=0.744 σ=0.136 grad),\n",
       " ('embeddings.LayerNorm.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.478, 0.568] μ=-0.010 σ=0.091 grad),\n",
       " ('transformer.layer.0.attention.q_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.705, 0.498] μ=6.249e-05 σ=0.043 grad),\n",
       " ('transformer.layer.0.attention.q_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-1.078, 1.100] μ=0.009 σ=0.324 grad),\n",
       " ('transformer.layer.0.attention.k_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.937, 0.782] μ=1.131e-05 σ=0.043 grad),\n",
       " ('transformer.layer.0.attention.k_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.012, 0.011] μ=-0.000 σ=0.003 grad),\n",
       " ('transformer.layer.0.attention.v_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.190, 0.200] μ=-7.438e-05 σ=0.034 grad),\n",
       " ('transformer.layer.0.attention.v_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.371, 0.420] μ=0.005 σ=0.081 grad),\n",
       " ('transformer.layer.0.attention.out_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.610, 0.740] μ=-2.041e-05 σ=0.035 grad),\n",
       " ('transformer.layer.0.attention.out_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.556, 0.135] μ=-0.001 σ=0.047 grad),\n",
       " ('transformer.layer.0.sa_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.505, 2.964] μ=0.841 σ=0.094 grad),\n",
       " ('transformer.layer.0.sa_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-4.308, 0.853] μ=-0.021 σ=0.336 grad),\n",
       " ('transformer.layer.0.ffn.lin1.weight',\n",
       "  Parameter[3072, 768] n=2359296 (9Mb) x∈[-0.346, 0.326] μ=-4.616e-06 σ=0.042 grad),\n",
       " ('transformer.layer.0.ffn.lin1.bias',\n",
       "  Parameter[3072] 12Kb x∈[-0.331, 0.428] μ=-0.112 σ=0.056 grad),\n",
       " ('transformer.layer.0.ffn.lin2.weight',\n",
       "  Parameter[768, 3072] n=2359296 (9Mb) x∈[-2.042, 0.913] μ=-9.168e-05 σ=0.043 grad),\n",
       " ('transformer.layer.0.ffn.lin2.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.531, 0.333] μ=-0.002 σ=0.084 grad),\n",
       " ('transformer.layer.0.output_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.105, 0.848] μ=0.747 σ=0.071 grad),\n",
       " ('transformer.layer.0.output_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-1.396, 0.419] μ=-0.042 σ=0.098 grad),\n",
       " ('transformer.layer.1.attention.q_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.539, 0.569] μ=-3.249e-06 σ=0.056 grad),\n",
       " ('transformer.layer.1.attention.q_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.891, 0.561] μ=0.001 σ=0.146 grad),\n",
       " ('transformer.layer.1.attention.k_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.582, 0.514] μ=4.283e-05 σ=0.055 grad),\n",
       " ('transformer.layer.1.attention.k_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.016, 0.027] μ=-3.028e-05 σ=0.004 grad),\n",
       " ('transformer.layer.1.attention.v_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.229, 0.261] μ=-0.000 σ=0.036 grad),\n",
       " ('transformer.layer.1.attention.v_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.307, 0.701] μ=0.004 σ=0.064 grad),\n",
       " ('transformer.layer.1.attention.out_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.459, 0.451] μ=-2.248e-06 σ=0.035 grad),\n",
       " ('transformer.layer.1.attention.out_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.432, 0.387] μ=-0.001 σ=0.096 grad),\n",
       " ('transformer.layer.1.sa_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.435, 2.061] μ=0.782 σ=0.091 grad),\n",
       " ('transformer.layer.1.sa_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-2.091, 0.711] μ=-0.018 σ=0.184 grad),\n",
       " ('transformer.layer.1.ffn.lin1.weight',\n",
       "  Parameter[3072, 768] n=2359296 (9Mb) x∈[-0.687, 0.603] μ=0.000 σ=0.045 grad),\n",
       " ('transformer.layer.1.ffn.lin1.bias',\n",
       "  Parameter[3072] 12Kb x∈[-0.356, 0.645] μ=-0.102 σ=0.070 grad),\n",
       " ('transformer.layer.1.ffn.lin2.weight',\n",
       "  Parameter[768, 3072] n=2359296 (9Mb) x∈[-4.034, 1.174] μ=-3.659e-05 σ=0.043 grad),\n",
       " ('transformer.layer.1.ffn.lin2.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.307, 0.304] μ=-0.001 σ=0.080 grad),\n",
       " ('transformer.layer.1.output_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.351, 0.933] μ=0.826 σ=0.072 grad),\n",
       " ('transformer.layer.1.output_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.322, 0.237] μ=-0.039 σ=0.071 grad),\n",
       " ('transformer.layer.2.attention.q_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.390, 0.391] μ=-0.000 σ=0.047 grad),\n",
       " ('transformer.layer.2.attention.q_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.755, 0.654] μ=0.003 σ=0.160 grad),\n",
       " ('transformer.layer.2.attention.k_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.340, 0.368] μ=3.938e-05 σ=0.047 grad),\n",
       " ('transformer.layer.2.attention.k_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.018, 0.022] μ=0.000 σ=0.005 grad),\n",
       " ('transformer.layer.2.attention.v_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.234, 0.236] μ=8.551e-05 σ=0.042 grad),\n",
       " ('transformer.layer.2.attention.v_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.202, 0.203] μ=-0.000 σ=0.033 grad),\n",
       " ('transformer.layer.2.attention.out_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.357, 0.303] μ=1.247e-05 σ=0.040 grad),\n",
       " ('transformer.layer.2.attention.out_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.203, 0.462] μ=0.000 σ=0.052 grad),\n",
       " ('transformer.layer.2.sa_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.410, 3.892] μ=0.749 σ=0.148 grad),\n",
       " ('transformer.layer.2.sa_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-1.331, 0.775] μ=-0.024 σ=0.158 grad),\n",
       " ('transformer.layer.2.ffn.lin1.weight',\n",
       "  Parameter[3072, 768] n=2359296 (9Mb) x∈[-0.795, 1.200] μ=0.000 σ=0.046 grad),\n",
       " ('transformer.layer.2.ffn.lin1.bias',\n",
       "  Parameter[3072] 12Kb x∈[-0.401, 0.536] μ=-0.104 σ=0.080 grad),\n",
       " ('transformer.layer.2.ffn.lin2.weight',\n",
       "  Parameter[768, 3072] n=2359296 (9Mb) x∈[-9.963, 2.184] μ=-2.582e-06 σ=0.045 grad),\n",
       " ('transformer.layer.2.ffn.lin2.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.325, 0.217] μ=-0.001 σ=0.058 grad),\n",
       " ('transformer.layer.2.output_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.480, 0.942] μ=0.811 σ=0.076 grad),\n",
       " ('transformer.layer.2.output_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.261, 0.255] μ=-0.036 σ=0.050 grad),\n",
       " ('transformer.layer.3.attention.q_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.271, 0.304] μ=-2.274e-06 σ=0.049 grad),\n",
       " ('transformer.layer.3.attention.q_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.956, 0.643] μ=-0.003 σ=0.159 grad),\n",
       " ('transformer.layer.3.attention.k_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.424, 0.479] μ=-7.917e-06 σ=0.049 grad),\n",
       " ('transformer.layer.3.attention.k_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.021, 0.020] μ=0.000 σ=0.005 grad),\n",
       " ('transformer.layer.3.attention.v_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.330, 0.271] μ=0.000 σ=0.046 grad),\n",
       " ('transformer.layer.3.attention.v_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.303, 0.214] μ=-0.003 σ=0.047 grad),\n",
       " ('transformer.layer.3.attention.out_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.279, 0.290] μ=-2.708e-05 σ=0.044 grad),\n",
       " ('transformer.layer.3.attention.out_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.221, 1.390] μ=0.001 σ=0.071 grad),\n",
       " ('transformer.layer.3.sa_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.481, 3.465] μ=0.739 σ=0.129 grad),\n",
       " ('transformer.layer.3.sa_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-2.168, 0.476] μ=-0.032 σ=0.155 grad),\n",
       " ('transformer.layer.3.ffn.lin1.weight',\n",
       "  Parameter[3072, 768] n=2359296 (9Mb) x∈[-0.383, 0.483] μ=0.001 σ=0.043 grad),\n",
       " ('transformer.layer.3.ffn.lin1.bias',\n",
       "  Parameter[3072] 12Kb x∈[-0.460, 0.616] μ=-0.110 σ=0.071 grad),\n",
       " ('transformer.layer.3.ffn.lin2.weight',\n",
       "  Parameter[768, 3072] n=2359296 (9Mb) x∈[-3.137, 0.994] μ=1.524e-05 σ=0.041 grad),\n",
       " ('transformer.layer.3.ffn.lin2.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.748, 0.226] μ=-0.000 σ=0.085 grad),\n",
       " ('transformer.layer.3.output_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.318, 1.154] μ=0.775 σ=0.050 grad),\n",
       " ('transformer.layer.3.output_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.227, 0.958] μ=-0.037 σ=0.065 grad),\n",
       " ('transformer.layer.4.attention.q_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.255, 0.247] μ=-0.000 σ=0.049 grad),\n",
       " ('transformer.layer.4.attention.q_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.785, 0.816] μ=0.007 σ=0.208 grad),\n",
       " ('transformer.layer.4.attention.k_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.586, 0.663] μ=-2.000e-06 σ=0.049 grad),\n",
       " ('transformer.layer.4.attention.k_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.025, 0.032] μ=9.841e-05 σ=0.007 grad),\n",
       " ('transformer.layer.4.attention.v_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.258, 0.236] μ=3.297e-05 σ=0.047 grad),\n",
       " ('transformer.layer.4.attention.v_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.240, 0.281] μ=-0.001 σ=0.040 grad),\n",
       " ('transformer.layer.4.attention.out_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.383, 0.437] μ=8.517e-06 σ=0.045 grad),\n",
       " ('transformer.layer.4.attention.out_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.189, 0.634] μ=0.001 σ=0.070 grad),\n",
       " ('transformer.layer.4.sa_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.553, 2.479] μ=0.732 σ=0.094 grad),\n",
       " ('transformer.layer.4.sa_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-1.466, 1.059] μ=-0.037 σ=0.138 grad),\n",
       " ('transformer.layer.4.ffn.lin1.weight',\n",
       "  Parameter[3072, 768] n=2359296 (9Mb) x∈[-0.885, 0.865] μ=0.001 σ=0.043 grad),\n",
       " ('transformer.layer.4.ffn.lin1.bias',\n",
       "  Parameter[3072] 12Kb x∈[-0.360, 0.603] μ=-0.110 σ=0.053 grad),\n",
       " ('transformer.layer.4.ffn.lin2.weight',\n",
       "  Parameter[768, 3072] n=2359296 (9Mb) x∈[-4.256, 2.376] μ=-1.810e-05 σ=0.042 grad),\n",
       " ('transformer.layer.4.ffn.lin2.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.666, 0.343] μ=-0.000 σ=0.084 grad),\n",
       " ('transformer.layer.4.output_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.093, 1.430] μ=0.777 σ=0.067 grad),\n",
       " ('transformer.layer.4.output_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.403, 0.384] μ=-0.039 σ=0.054 grad),\n",
       " ('transformer.layer.5.attention.q_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.646, 0.624] μ=-0.000 σ=0.049 grad),\n",
       " ('transformer.layer.5.attention.q_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.863, 0.857] μ=0.013 σ=0.239 grad),\n",
       " ('transformer.layer.5.attention.k_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.449, 0.285] μ=0.000 σ=0.049 grad),\n",
       " ('transformer.layer.5.attention.k_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.023, 0.033] μ=-0.000 σ=0.005 grad),\n",
       " ('transformer.layer.5.attention.v_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.313, 0.259] μ=2.113e-05 σ=0.048 grad),\n",
       " ('transformer.layer.5.attention.v_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.136, 0.083] μ=0.000 σ=0.022 grad),\n",
       " ('transformer.layer.5.attention.out_lin.weight',\n",
       "  Parameter[768, 768] n=589824 (2.2Mb) x∈[-0.506, 0.419] μ=5.087e-08 σ=0.045 grad),\n",
       " ('transformer.layer.5.attention.out_lin.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.154, 0.190] μ=-0.000 σ=0.051 grad),\n",
       " ('transformer.layer.5.sa_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.600, 1.538] μ=0.772 σ=0.059 grad),\n",
       " ('transformer.layer.5.sa_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-2.148, 0.387] μ=-0.046 σ=0.109 grad),\n",
       " ('transformer.layer.5.ffn.lin1.weight',\n",
       "  Parameter[3072, 768] n=2359296 (9Mb) x∈[-0.423, 0.502] μ=0.001 σ=0.039 grad),\n",
       " ('transformer.layer.5.ffn.lin1.bias',\n",
       "  Parameter[3072] 12Kb x∈[-0.451, 0.585] μ=-0.077 σ=0.059 grad),\n",
       " ('transformer.layer.5.ffn.lin2.weight',\n",
       "  Parameter[768, 3072] n=2359296 (9Mb) x∈[-3.187, 1.086] μ=-6.087e-06 σ=0.037 grad),\n",
       " ('transformer.layer.5.ffn.lin2.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.584, 0.145] μ=-0.001 σ=0.058 grad),\n",
       " ('transformer.layer.5.output_layer_norm.weight',\n",
       "  Parameter[768] 3Kb x∈[0.215, 0.748] μ=0.606 σ=0.029 grad),\n",
       " ('transformer.layer.5.output_layer_norm.bias',\n",
       "  Parameter[768] 3Kb x∈[-0.171, 0.365] μ=-0.021 σ=0.048 grad)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l for l in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d27f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torchinfo/torchinfo.py:295\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torch/nn/modules/module.py:387\u001b[39m, in \u001b[36m_forward_unimplemented\u001b[39m\u001b[34m(self, *input)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[32m    378\u001b[39m \n\u001b[32m    379\u001b[39m \u001b[33;03mShould be overridden by all subclasses.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m \u001b[33;03m    registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[32m    386\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    388\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing the required \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m function\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    389\u001b[39m )\n",
      "\u001b[31mNotImplementedError\u001b[39m: Module [DistilBertPreTrainedModel] is missing the required \"forward\" function",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torchinfo/torchinfo.py:223\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m validate_user_params(\n\u001b[32m    217\u001b[39m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[32m    218\u001b[39m )\n\u001b[32m    220\u001b[39m x, correct_input_size = process_input(\n\u001b[32m    221\u001b[39m     input_data, input_size, batch_dim, device, dtypes\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m summary_list = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m formatting = FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[32m    227\u001b[39m results = ModelStatistics(\n\u001b[32m    228\u001b[39m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/Adhoc/projects/learning-ai/learn-env/lib/python3.12/site-packages/torchinfo/torchinfo.py:304\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    303\u001b[39m     executed_layers = [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer.executed]\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c7446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
