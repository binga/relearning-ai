{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312caa2e",
   "metadata": {},
   "source": [
    "# CS336 Assignments\n",
    "\n",
    "| # | Topic                         | Description                                 |\n",
    "|---|-------------------------------|---------------------------------------------|\n",
    "| 1 | Basics                        | Train an LLM from scratch                   |\n",
    "| 2 | Systems                       | Make it run fast!                           |\n",
    "| 3 | Scaling                       | Make it performant at a FLOP budget         |\n",
    "| 4 | Data                          | Prepare the right datasets                  |\n",
    "| 5 | Alignment & Reasoning RL      | Align it to real-world use cases            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788fc7b",
   "metadata": {},
   "source": [
    "# Assignment #1\n",
    "- Implement all of the components (tokenizer, model, loss function, optimizer) necessary to train a standard Transformer language model\n",
    "- Train a minimal language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53228e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e9b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2119719\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 21990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hf = load_dataset(\"roneneldan/TinyStories\")\n",
    "data_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a0fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"Your journey starts with one step\"\n",
    "sample_sentence\n",
    "\n",
    "emb_matrix = torch.tensor([\n",
    "    [0.43, 0.15, 0.89],\n",
    "    [0.55, 0.87, 0.66],\n",
    "    [0.57, 0.85, 0.64],\n",
    "    [0.22, 0.58, 0.33],\n",
    "    [0.77, 0.25, 0.10],\n",
    "    [0.05, 0.80, 0.55]    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c496f663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7120, 7002, 4940, 351, 530, 2239]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttok = tiktoken.get_encoding(\"gpt2\")\n",
    "ttok.encode(sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb638aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f6c8297",
   "metadata": {},
   "source": [
    "## Code a simplified self-attention model without trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d900b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 6] n=36 x∈[0.294, 1.495] μ=0.806 σ=0.333\n",
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = emb_matrix @ emb_matrix.T\n",
    "attn_scores.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c85a0ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 6] n=36 x∈[0.063, 0.233] μ=0.167 σ=0.052\n",
       "tensor([[0.2241, 0.2140, 0.2113, 0.1066, 0.1026, 0.1415],\n",
       "        [0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656],\n",
       "        [0.1454, 0.2277, 0.2248, 0.1280, 0.1104, 0.1637],\n",
       "        [0.1304, 0.2313, 0.2275, 0.1354, 0.0953, 0.1801],\n",
       "        [0.1436, 0.2219, 0.2245, 0.1090, 0.2088, 0.0921],\n",
       "        [0.1350, 0.2325, 0.2269, 0.1405, 0.0628, 0.2022]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = attn_scores / attn_scores.sum(dim=1, keepdim=True)\n",
    "attn_weights.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c975ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 6] n=36 x∈[0.156, 0.183] μ=0.167 σ=0.005\n",
       "tensor([[0.1787, 0.1647, 0.1647, 0.1637, 0.1645, 0.1639],\n",
       "        [0.1652, 0.1670, 0.1669, 0.1673, 0.1654, 0.1679],\n",
       "        [0.1652, 0.1670, 0.1669, 0.1672, 0.1658, 0.1676],\n",
       "        [0.1627, 0.1676, 0.1674, 0.1685, 0.1633, 0.1704],\n",
       "        [0.1649, 0.1660, 0.1669, 0.1641, 0.1829, 0.1560],\n",
       "        [0.1635, 0.1678, 0.1673, 0.1693, 0.1581, 0.1742]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_weights, dim=0)\n",
    "attn_weights.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de339bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 3] n=18 x∈[0.426, 0.590] μ=0.514 σ=0.065\n",
       "tensor([[0.4321, 0.5772, 0.5337],\n",
       "        [0.4305, 0.5846, 0.5281],\n",
       "        [0.4308, 0.5844, 0.5279],\n",
       "        [0.4288, 0.5873, 0.5281],\n",
       "        [0.4421, 0.5767, 0.5213],\n",
       "        [0.4256, 0.5897, 0.5307]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = attn_weights @ emb_matrix\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d51ac",
   "metadata": {},
   "source": [
    "## Code a simplified self-attention model with trainable weights\n",
    "\n",
    "This self-attention is also called as scaled dot product attention.\n",
    "\n",
    "Instead of directly computing `attn_scores` from the embedding matrix, we want to do a weighted multiplication with input vectors. This helps in identifying \"good context vectors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0565018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 3] n=18 x∈[0.050, 0.890] μ=0.514 σ=0.276\n",
       "tensor([[0.4300, 0.1500, 0.8900],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ecaee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor[3, 2] n=6 x∈[-1.123, 0.337] μ=-0.063 σ=0.549 [[0.337, 0.129], [0.234, 0.230], [-1.123, -0.186]]\n",
       " tensor([[ 0.3367,  0.1288],\n",
       "         [ 0.2345,  0.2303],\n",
       "         [-1.1229, -0.1863]]),\n",
       " tensor[3, 2] n=6 x∈[-0.638, 2.208] μ=0.607 σ=0.927 [[2.208, -0.638], [0.462, 0.267], [0.535, 0.809]]\n",
       " tensor([[ 2.2082, -0.6380],\n",
       "         [ 0.4617,  0.2674],\n",
       "         [ 0.5349,  0.8094]]),\n",
       " tensor[3, 2] n=6 x∈[-1.690, 1.322] μ=0.255 σ=1.266 [[1.110, -1.690], [-0.989, 0.958], [1.322, 0.817]]\n",
       " tensor([[ 1.1103, -1.6898],\n",
       "         [-0.9890,  0.9580],\n",
       "         [ 1.3221,  0.8172]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "W_query = torch.randn((3, 2))\n",
    "W_key = torch.randn((3, 2))\n",
    "W_value = torch.randn((3, 2))\n",
    "\n",
    "W_query.v, W_key.v, W_value.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0cc53f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor[6, 2] n=12 x∈[-0.819, 0.206] μ=-0.110 σ=0.314\n",
       " tensor([[-0.8194, -0.0759],\n",
       "         [-0.3519,  0.1483],\n",
       "         [-0.3274,  0.1500],\n",
       "         [-0.1605,  0.1004],\n",
       "         [ 0.2056,  0.1381],\n",
       "         [-0.4132,  0.0882]]),\n",
       " tensor[6, 2] n=12 x∈[-0.343, 1.993] μ=0.907 σ=0.758\n",
       " tensor([[ 1.4948,  0.4861],\n",
       "         [ 1.9692,  0.4159],\n",
       "         [ 1.9934,  0.3816],\n",
       "         [ 0.9301,  0.2818],\n",
       "         [ 1.8692, -0.3435],\n",
       "         [ 0.7739,  0.6271]]),\n",
       " tensor[6, 2] n=12 x∈[-0.980, 1.506] μ=0.431 σ=0.618\n",
       " tensor([[ 1.5058,  0.1444],\n",
       "         [ 0.6229,  0.4434],\n",
       "         [ 0.6384,  0.3741],\n",
       "         [ 0.1070,  0.4535],\n",
       "         [ 0.7399, -0.9799],\n",
       "         [-0.0085,  1.1313]]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = emb_matrix @ W_query\n",
    "key = emb_matrix @ W_key\n",
    "value = emb_matrix @ W_value\n",
    "\n",
    "query.v, key.v, value.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a48143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 6] n=36 x∈[0.153, 0.188] μ=0.167 σ=0.005\n",
       "tensor([[0.1670, 0.1633, 0.1626, 0.1663, 0.1526, 0.1882],\n",
       "        [0.1666, 0.1671, 0.1672, 0.1667, 0.1687, 0.1638],\n",
       "        [0.1665, 0.1672, 0.1673, 0.1667, 0.1691, 0.1632],\n",
       "        [0.1665, 0.1672, 0.1673, 0.1667, 0.1691, 0.1632],\n",
       "        [0.1661, 0.1685, 0.1689, 0.1666, 0.1758, 0.1541],\n",
       "        [0.1667, 0.1663, 0.1663, 0.1667, 0.1652, 0.1688]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = query @ key.T\n",
    "attn_weights = attn_scores / attn_scores.sum(dim=0, keepdim=True)\n",
    "attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "attn_weights.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77dd7ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 2] n=12 x∈[0.239, 0.609] μ=0.431 σ=0.178\n",
       "tensor([[0.5861, 0.2962],\n",
       "        [0.6029, 0.2562],\n",
       "        [0.6033, 0.2553],\n",
       "        [0.6033, 0.2553],\n",
       "        [0.6095, 0.2395],\n",
       "        [0.5994, 0.2648]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = attn_weights @ value\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6befa8b",
   "metadata": {},
   "source": [
    "### Pytorchification of SelfAttention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7e044df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 2] n=12 x∈[0.239, 0.609] μ=0.431 σ=0.178 grad MmBackward0\n",
       "tensor([[0.5861, 0.2962],\n",
       "        [0.6029, 0.2562],\n",
       "        [0.6033, 0.2553],\n",
       "        [0.6033, 0.2553],\n",
       "        [0.6095, 0.2395],\n",
       "        [0.5994, 0.2648]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_key   = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, emb_sz)\n",
    "        query = x @ self.W_query # query shape: (seq_len, d_out)\n",
    "        key   = x @ self.W_key # key shape: (seq_len, d_out)\n",
    "        value = x @ self.W_value # value shape: (seq_len, d_out)\n",
    "\n",
    "        attn_scores = query @ key.T # attn_scores shape: (seq_len, seq_len)\n",
    "        attn_weights = attn_scores / attn_scores.sum(dim=0, keepdim=True)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = SelfAttention(3, 2)\n",
    "out = model(emb_matrix)\n",
    "out.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca0b52",
   "metadata": {},
   "source": [
    "There have been numerous studies that suggest to do a normalization with d_out ** 0.5 prior to softmax. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4cc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 2] n=12 x∈[0.254, 0.618] μ=0.441 σ=0.136 grad MmBackward0\n",
       "tensor([[0.5141, 0.3639],\n",
       "        [0.5633, 0.3251],\n",
       "        [0.5659, 0.3221],\n",
       "        [0.5839, 0.2941],\n",
       "        [0.6180, 0.2539],\n",
       "        [0.5575, 0.3262]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_key   = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, emb_sz)\n",
    "        query = x @ self.W_query # query shape: (seq_len, d_out)\n",
    "        key   = x @ self.W_key # key shape: (seq_len, d_out)\n",
    "        value = x @ self.W_value # value shape: (seq_len, d_out)\n",
    "\n",
    "        attn_scores = query @ key.T # attn_scores shape: (seq_len, seq_len)\n",
    "        attn_weights = attn_scores / query.shape[1] ** 0.5 # normalizing with sqrt(d_out)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model = SelfAttention(3, 2)\n",
    "out = model(emb_matrix)\n",
    "out.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef1831",
   "metadata": {},
   "source": [
    "## Code a self-attention model with causal attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b268cc5",
   "metadata": {},
   "source": [
    "For next token prediction, we attend to words prior to the current word and hence we cannot access future words. This means, our attention cannot be extended to the complete sequence but just the words prior. This is called causal attention. Let's go ahead and mask the attention with future tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64992a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor[3, 2] n=6 x∈[-1.123, 0.337] μ=-0.063 σ=0.549 [[0.337, 0.129], [0.234, 0.230], [-1.123, -0.186]]\n",
       " tensor([[ 0.3367,  0.1288],\n",
       "         [ 0.2345,  0.2303],\n",
       "         [-1.1229, -0.1863]]),\n",
       " tensor[3, 2] n=6 x∈[-0.638, 2.208] μ=0.607 σ=0.927 [[2.208, -0.638], [0.462, 0.267], [0.535, 0.809]]\n",
       " tensor([[ 2.2082, -0.6380],\n",
       "         [ 0.4617,  0.2674],\n",
       "         [ 0.5349,  0.8094]]),\n",
       " tensor[3, 2] n=6 x∈[-1.690, 1.322] μ=0.255 σ=1.266 [[1.110, -1.690], [-0.989, 0.958], [1.322, 0.817]]\n",
       " tensor([[ 1.1103, -1.6898],\n",
       "         [-0.9890,  0.9580],\n",
       "         [ 1.3221,  0.8172]]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "W_query = torch.randn((3, 2))\n",
    "W_key = torch.randn((3, 2))\n",
    "W_value = torch.randn((3, 2))\n",
    "\n",
    "W_query.v, W_key.v, W_value.v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e97f098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = emb_matrix @ W_query\n",
    "key = emb_matrix @ W_key\n",
    "value = emb_matrix @ W_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84ec68ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor[6, 6] n=36 x∈[-1.262, 0.463] μ=-0.310 σ=0.468 \u001b[31m-Inf!\u001b[0m\n",
       " tensor([[-1.2618,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.4540, -0.6313,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.4166, -0.5824, -0.5955,    -inf,    -inf,    -inf],\n",
       "         [-0.1911, -0.2742, -0.2816, -0.1210,    -inf,    -inf],\n",
       "         [ 0.3745,  0.4623,  0.4625,  0.2301,  0.3368,    -inf],\n",
       "         [-0.5747, -0.7769, -0.7900, -0.3594, -0.8026, -0.2644]]),\n",
       " tensor[6, 6] n=36 x∈[0., 1.000] μ=0.167 σ=0.204\n",
       " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5313, 0.4687, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3609, 0.3210, 0.3181, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2543, 0.2398, 0.2386, 0.2673, 0.0000, 0.0000],\n",
       "         [0.1998, 0.2126, 0.2126, 0.1804, 0.1946, 0.0000],\n",
       "         [0.1670, 0.1448, 0.1435, 0.1945, 0.1422, 0.2080]]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = query @ key.T\n",
    "attn_scores.v\n",
    "\n",
    "causal_mask = torch.triu(torch.ones(6, 6), diagonal=1)\n",
    "attn_scores = attn_scores.masked_fill(causal_mask.bool(), -torch.inf)\n",
    "attn_scores.v\n",
    "\n",
    "\n",
    "attn_weights = attn_scores / query.shape[1] ** 0.5\n",
    "# attn_scores.v, attn_weights.v\n",
    "\n",
    "attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "attn_scores.v, attn_weights.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "507667b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 2] n=12 x∈[0.094, 1.506] μ=0.589 σ=0.426\n",
       "tensor([[1.5058, 0.1444],\n",
       "        [1.0920, 0.2845],\n",
       "        [0.9465, 0.3134],\n",
       "        [0.7133, 0.3535],\n",
       "        [0.7323, 0.0938],\n",
       "        [0.5575, 0.3262]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = attn_weights @ value\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977359d8",
   "metadata": {},
   "source": [
    "Let's combine this into a contained class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fc77e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 2] n=12 x∈[0.093, 1.506] μ=0.588 σ=0.425 grad MmBackward0\n",
       "tensor([[1.5058, 0.1444],\n",
       "        [1.0869, 0.2862],\n",
       "        [0.9420, 0.3148],\n",
       "        [0.7143, 0.3536],\n",
       "        [0.7306, 0.0925],\n",
       "        [0.5660, 0.3140]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CausalAttention_v1(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_key  = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, emb_sz)\n",
    "\n",
    "        seq_len, emb_sz = x.shape\n",
    "        query = x @ self.W_query\n",
    "        key   = x @ self.W_key\n",
    "        value = x @ self.W_value\n",
    "\n",
    "        attn_scores = query @ key.T\n",
    "        \n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "        attn_scores = attn_scores.masked_fill(causal_mask.bool(), -torch.inf)\n",
    "\n",
    "        attn_scores = attn_scores / emb_sz ** 0.5\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = CausalAttention_v1(3, 2)\n",
    "context_vec = model(emb_matrix)\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a02cd0",
   "metadata": {},
   "source": [
    "It's a common practice to add a dropout layer right after computing the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[6, 2] n=12 x∈[-0.139, 2.174] μ=0.643 σ=0.758 grad MmBackward0\n",
       "tensor([[ 0.0000,  0.0000],\n",
       "        [ 2.1738,  0.5725],\n",
       "        [ 1.8840,  0.6295],\n",
       "        [ 0.6649,  0.6339],\n",
       "        [ 1.1534, -0.1391],\n",
       "        [ 0.2575, -0.1156]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CausalAttention_v2(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, drop_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_key  = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.dropout = torch.nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, emb_sz)\n",
    "\n",
    "        seq_len, emb_sz = x.shape\n",
    "        query = x @ self.W_query\n",
    "        key   = x @ self.W_key\n",
    "        value = x @ self.W_value\n",
    "\n",
    "        attn_scores = query @ key.T\n",
    "        \n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "        attn_scores = attn_scores.masked_fill(causal_mask.bool(), -torch.inf)\n",
    "\n",
    "        attn_scores = attn_scores / emb_sz ** 0.5\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = CausalAttention_v2(3, 2)\n",
    "context_vec = model(emb_matrix)\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b791f",
   "metadata": {},
   "source": [
    "As there will be many data points as an input to the model, let's grab them into a batch and pass them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a3de66a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 3] n=36 x∈[0.050, 0.890] μ=0.514 σ=0.272\n",
       "tensor([[[0.4300, 0.1500, 0.8900],\n",
       "         [0.5500, 0.8700, 0.6600],\n",
       "         [0.5700, 0.8500, 0.6400],\n",
       "         [0.2200, 0.5800, 0.3300],\n",
       "         [0.7700, 0.2500, 0.1000],\n",
       "         [0.0500, 0.8000, 0.5500]],\n",
       "\n",
       "        [[0.4300, 0.1500, 0.8900],\n",
       "         [0.5500, 0.8700, 0.6600],\n",
       "         [0.5700, 0.8500, 0.6400],\n",
       "         [0.2200, 0.5800, 0.3300],\n",
       "         [0.7700, 0.2500, 0.1000],\n",
       "         [0.0500, 0.8000, 0.5500]]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.stack([emb_matrix, emb_matrix], dim=0)\n",
    "batch.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "626394b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 2] n=24 x∈[-0.139, 3.012] μ=0.674 σ=0.797 grad UnsafeViewBackward0\n",
       "tensor([[[ 0.0000,  0.0000],\n",
       "         [ 2.1738,  0.5725],\n",
       "         [ 1.8840,  0.6295],\n",
       "         [ 0.6649,  0.6339],\n",
       "         [ 1.1534, -0.1391],\n",
       "         [ 0.2575, -0.1156]],\n",
       "\n",
       "        [[ 3.0116,  0.2888],\n",
       "         [ 1.5828,  0.1518],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 1.1213,  0.5271],\n",
       "         [ 0.8639,  0.2442],\n",
       "         [ 0.4022,  0.2759]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modified the softmax to consider the last dimension to normalize.\n",
    "\n",
    "class CausalAttention_v3(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, drop_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_key  = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.dropout = torch.nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, emb_sz)\n",
    "\n",
    "        batch_sz, seq_len, emb_sz = x.shape\n",
    "        query = x @ self.W_query # query shape: (batch_size, seq_len, d_out)\n",
    "        key   = x @ self.W_key # key shape: (batch_size, seq_len, d_out)\n",
    "        value = x @ self.W_value # value shape: (batch_size, seq_len, d_out)\n",
    "\n",
    "        attn_scores = query @ key.transpose(1, 2) # (transposing 1st and 2nd dimension for matmul)\n",
    "        \n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1) \n",
    "        attn_scores = attn_scores.masked_fill(causal_mask.bool(), -torch.inf)\n",
    "\n",
    "        attn_scores = attn_scores / emb_sz ** 0.5\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = CausalAttention_v3(3, 2)\n",
    "context_vec = model(batch)\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6c5b1",
   "metadata": {},
   "source": [
    "We see that the output is the right size (2, 6, 2) which is (batch_size, seq_len, d_out).\n",
    "\n",
    "However, for the curious, the 1st element output is different from 2nd element even though we passed the exact same input via `torch.stack([emb_matrix, emb_matrix])`. Why is that the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7e4a7",
   "metadata": {},
   "source": [
    "The answer is Dropout! As dropout layer is randomly cutting off a few weights, we see the outputs changing. If we turn off the dropout layer, we see that the output is same across the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ddedae0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6, 2] n=24 x∈[0.093, 1.506] μ=0.588 σ=0.416 grad UnsafeViewBackward0\n",
       "tensor([[[1.5058, 0.1444],\n",
       "         [1.0869, 0.2862],\n",
       "         [0.9420, 0.3148],\n",
       "         [0.7143, 0.3536],\n",
       "         [0.7306, 0.0925],\n",
       "         [0.5660, 0.3140]],\n",
       "\n",
       "        [[1.5058, 0.1444],\n",
       "         [1.0869, 0.2862],\n",
       "         [0.9420, 0.3148],\n",
       "         [0.7143, 0.3536],\n",
       "         [0.7306, 0.0925],\n",
       "         [0.5660, 0.3140]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modified the softmax to consider the last dimension to normalize.\n",
    "\n",
    "class CausalAttention_v4(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, drop_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_key  = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=True)\n",
    "        self.dropout = torch.nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, emb_sz)\n",
    "\n",
    "        batch_sz, seq_len, emb_sz = x.shape\n",
    "        query = x @ self.W_query # query shape: (batch_size, seq_len, d_out)\n",
    "        key   = x @ self.W_key # key shape: (batch_size, seq_len, d_out)\n",
    "        value = x @ self.W_value # value shape: (batch_size, seq_len, d_out)\n",
    "\n",
    "        attn_scores = query @ key.transpose(1, 2) # (transposing 1st and 2nd dimension for matmul)\n",
    "        \n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1) \n",
    "        attn_scores = attn_scores.masked_fill(causal_mask.bool(), -torch.inf)\n",
    "\n",
    "        attn_scores = attn_scores / emb_sz ** 0.5\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        # attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = attn_weights @ value\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = CausalAttention_v4(3, 2)\n",
    "context_vec = model(batch)\n",
    "context_vec.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466114fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7453cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
